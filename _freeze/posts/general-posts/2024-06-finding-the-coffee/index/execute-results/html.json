{
  "hash": "87156b37f31f43f3c192b4b8b51782e0",
  "result": {
    "markdown": "---\ntitle: \"Finding all The Coffee shops in Brazil\"\ndate: \"2024-06-12\"\ndescription: \"\"\ncategories: ['data-science', 'web-scrapping', 'finding-all', 'tutorial-r', 'brasil']\nexecute: \n  eval: false\ndraft: true\n---\n\n\n# Finding all The Coffee shops in Brazil\n\nIn this post, I'll show you how to map every The Coffee shop in Brazil in less time than it takes to brew a pot of coffee. All this from your laptop and without spending a dime.\n\nWe'll use only `R` and a few packages to webscrape all addresses.\n\n### What is The Coffee\n\nThe Coffee is a Japanese-inspired chain of coffee shops with a distinct minimalist visual identity. Their street shops are small, clean, and extremely space-efficient, sometimes taking less than 20 m2. They offer a wide variety of high quality coffee at a premium price point.\n\nSimilar to Starbucks, product customization is a major selling point. Customers can choose and replace pretty much everything in their drinks, from adding and additional espresso shot, requiring an additional pump of chocolate syrup. Unlike Starbucks, however, most The Coffee shops are strictly to-go, or offer only minimal seating capacity. The Coffee doesn't aim at becoming a 3rd place, where friends meet to share a cup of coffee, or work colleagues schedule a meeting.\n\nThe Coffee also strays away from the traditional friendly-neighborhood barista and instead focuses on a more technological approach. Customers mainly interact with a tablet that displays the menu and all customization choices. Friendly chatter is an optional, as a customer can get in, get his coffee without exchaning any words with the barista.\n\nThe company was founded in Curitiba, at the southern part of Brazil, in 2018, and has expanded rapidly to 12 countries with over 200 shops. Their franchise model in part explains this strong expansion.\n\n# Webscraping\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(rvest)\nlibrary(sf)\nlibrary(leaflet)\n\nimport::from(tidygeocoder, geocode)\nimport::from(purrr, map, map2)\nimport::from(tidyr, unnest)\n```\n:::\n\n\n## Finding the data\n\n### The website\n\n![](/static/images/coffeeshops/tcf_site.png){fig-align=\"center\"}\n\n![](/static/images/coffeeshops/tcf_inspect.png){fig-align=\"center\"}\n\n### Using R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Base url \nbase_url <- \"https://thecoffee.jp/shortcut/brasil\"\n# Parse HTML\npage_list_brazil <- xml2::read_html(base_url)\n\npage_list_cities <- page_list_brazil |> \n  html_elements(xpath = \"//div/ul/li/a\") |> \n  html_attr(\"href\")\n\npage_list_cities <- page_list_cities[str_detect(page_list_cities, \"brasil/\")]\n\nurl_cities <- str_c(base_url, str_remove(page_list_cities, \"shortcut/brasil/\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nscrape_the_coffee <- function(url) {\n  \n  # Parse the html\n  page <- xml2::read_html(url)\n  # Find the the name of the shop\n  coffee_shop_name <- page |> \n    rvest::html_elements(xpath = \"//div/ul/li/div/div/a/h4\") |> \n    rvest::html_text()\n  # Find the address of the shop\n  address_list <- page |> \n    rvest::html_elements(xpath = \"//div/ul/li/div/div/a/p\") |> \n    rvest::html_text()\n  # Remove shops that are not open yet\n  address_list <- address_list[!str_detect(address_list, \"coming soon\")]\n  street_name <- address_list[seq(1, length(address_list), 2)]\n  city_name <- address_list[2]\n  \n  full_address <- paste(street_name, city_name)\n\n  # Store results in a tibble\n  out <- tibble::tibble(\n    name = coffee_shop_name,\n    address = full_address,\n    street_name = street_name,\n    city_name = city_name\n  )\n  \n  return(out)\n\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scrape all cities\ncoffee_locations <- map(url_cities, scrape_the_coffee)\nnames(coffee_locations) <- url_cities\ndat <- bind_rows(coffee_locations, .id = \"url\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npb <- txtProgressBar(min = 1, max = length(url_cities), style = 3)\nls <- vector(\"list\", length(url_cities))\n\nfor (i in seq_along(url_cities)) {\n  \n  url <- url_cities[i]\n  current_city <- basename(url)\n  message(\"Scraping data for: \", current_city)\n  ls[[i]] <- scrape_the_coffee(url)\n  setTxtProgressBar(pb, i)\n  \n}\n```\n:::\n\n\n### Cleaning the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunnabreviate <- function() {\n  c(\"Av\\\\.\" = \"Avenida\",\n    \"Al\\\\.\" = \"Alameda\",\n    \"R\\\\.\"  = \"Rua\",\n    \"Dr\\\\.\" = \"Doutor\",\n    \"Visc\\\\.\" = \"Visconde\",\n    \"Pres\\\\.\" = \"Presidente\",\n    \"Mal\\\\.\" = \"Marechal\")\n}\n\ndat <- dat |> \n  mutate(\n    city_name = str_remove(city_name, \" - Brasil\"),\n    address = str_replace_all(address, unnabreviate()),\n    country = \"Brasil\"\n    )\n```\n:::\n\n\n### Geocoding\n\nGeocoding the data is fairly straightforward. I use the Google Maps API to find the corresponding lat/lng pair for each address.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Geocode using Maps API\ncoffee <- tidygeocoder::geocode(\n  dat,\n  address = address,\n  method = \"google\"\n  )\n\n# Convert to spatial data.frame\nshops <- st_as_sf(\n  coffee,\n  coords = c(\"long\", \"lat\"),\n  crs = 4326,\n  remove = FALSE\n  )\n```\n:::\n\n\n## Results\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_count <- shops |> \n  st_drop_geometry() |> \n  count(city_name, sort = TRUE) |> \n  mutate(share_brasil = n / sum(n)) |> \n  head(10)\n\ngt(tab_count, caption = \"The Coffee shops, major cities\") |> \n  cols_label(\n    city_name = \"Cidade\",\n    n = \"Lojas\",\n    share_brasil = \"Share BR (%)\"\n  ) |> \n  fmt_percent(3) |> \n  opt_stylize(style = 6) |> \n  opt_table_font(font = google_font(\"Open Sans\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nleaflet(shops) %>%\n  addTiles() %>%\n  addMarkers(label = ~name) %>%\n  addProviderTiles(\"CartoDB\") %>%\n  setView(lng = -46.65590, lat = -23.561197, zoom = 12)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncur_shops <- filter(shops, city_name == \"Curitiba\")\n\nget_ratings <- function(lat, lng) {\n  \n  location <- c(lat, lng)\n  places <- google_places(\"The Coffee\", location = location, radius = 10)\n  res <- places$results\n  \n  subres <- res %>%\n    unnest(cols = \"geometry\") %>%\n    unnest(cols = \"location\") %>%\n    select(\n      business_status, name, formatted_address, rating, user_ratings_total,\n      lat, lng\n    )\n  \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nratings <- map2(cur_shops$lat, cur_shops$long, get_ratings)\n\ndat_ratings <- ratings |> \n  bind_rows() |> \n  distinct() |> \n  filter(str_detect(name, \"^The Coffee\"))\n\ndat_ratings <- dat_ratings |> \n  mutate(\n    street_name = str_extract(formatted_address, \"^[^,]+\"),\n    street_name = str_replace_all(street_name, unnabreviate()),\n    street_name = stringi::stri_trans_general(street_name, \"latin-ascii\"),\n    street_number = as.numeric(str_extract(formatted_address, \"(?<=, )\\\\d+(?=\\\\b)\"))\n  )\n\ncur_shops <- cur_shops |> \n  rename(short_address = street_name) |> \n  mutate(\n    street_name = str_extract(address, \"^[^,]+\"),\n    street_name = str_replace_all(street_name, unnabreviate()),\n    street_name = stringi::stri_trans_general(street_name, \"latin-ascii\"),\n    street_number = as.numeric(str_extract(address, \"(?<=, )\\\\d+(?=\\\\b)\"))\n  )\n\ncur_shops |> \n  arrange(address) |> \n  left_join(dat_ratings, by = c(\"street_name\", \"street_number\")) |> \n  filter(is.na(rating))\n\ndat_ratings$street_name\n\nsubres <- st_as_sf(subres, coords = c(\"lng\", \"lat\"), crs = 4326)\n\n# Mapa iterativo simples\nleaflet(subres) |> \n  addTiles() |> \n  addCircleMarkers(label = ~name) |> \n  addProviderTiles(\"CartoDB\")\n```\n:::\n\n\n## Merging with Census information\n\n\n::: {.cell}\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}