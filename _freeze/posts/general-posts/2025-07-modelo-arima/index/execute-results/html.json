{
  "hash": "80b3199e80f3715226242c4f8ffa6694",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Modelo ARIMA no R\"\ndate: \"2025-07-01\"\ncategories: ['data-science', 'time-series', 'econometria']\ndescription: \"\"\nformat: html\nexecute:\n  warning: false\n  message: false\ndraft: true\n---\n\n\n\n# O modelo\n\nA teoria dos [modelos ARMA(p,q)](https://restateinsight.com/posts/general-posts/repost-arma-exemplo-simples/) serve apenas para séries estiacionárias; na prática, contudo, é bastante frequente encontrar séries não-estacionárias. Séries com tendência de crescimento ou cuja variância aumenta ao longo do tempo são exemplos típicos de não-estacionaridade que encontra-se nos dados.\n\nA ideia da modelagem ARIMA é de tirar diferenças na série original de forma a torná-la estacionária. Isto é, se tivermos uma série $y_{t}$ que não é estacionária, vamos transformá-la em $x_{t} \\equiv y_{t} - y_{t-1}$ para torná-la estacionária.\n\nNeste caso, a série $x_{t}$ é chamada a primeira diferença de $y_{t}$. Eventualmente será necessário tirar mais do que uma diferença para tornar a série estacionária.\n\n## Contexto\n\nA análise de séries temporais ocupa um lugar central na macroeconomia moderna, fornecendo ferramentas essenciais para compreender a dinâmica das principais variáveis econômicas. Os modelos ARIMA (AutoRegressive Integrated Moving Average) representam uma das abordagens mais consolidadas e amplamente utilizadas para modelagem de séries temporais univariadas.\n\nO ARIMA combina simplicidade e boa capacidade preditiva. Neste sentido, ele serve tanto como uma ferramenta central, dentro de uma análise macroeconômica, como também como benchmark para modelos mais sofisticados.\n\n### R\n\nA modelagem de séries temporais no `R` é um tanto caótica. Isto acontece pela diversidade e complexidade de dados em séries de tempo. Via de regra, as funções-base do `R` servem muito bem para séries mensais, trimestrais e anuais. Quando se lida, por exemplo, com dados financeiros diários ou intra-diários costuma ser necessário usar pacotes especializados.\n\nCom o tempo, as funções base do `R` se tornaram um tanto defasadas. Os gráficos do `R` foram revolucionados pelo pacote `ggplot2` mas a sua sintaxe não funciona tão diretamente com séries de tempo; como resultado, alguns ajustes são necessários para compatibilizar os dois.\n\nNeste post, tentei manter o código o mais simples possível usando somente o pacote `forecast`[^1], que é excelente para o tratamento de séries de tempo univariadas[^2]. Abaixo segue a lista dos pacotes necessários para acompanhar este post[^3].\n\n[^1]: Para mais sobre o pacote `forecast` vale consultar o livro [Forecasting: Principles and Practice](https://otexts.com/fpp2/).\n\n[^2]: O pacote `forecast` começa a ficar um pouco limitado quando se lida com muitas séries de tempo (e.g. mais de 20).\n\n[^3]: Alguns pacotes adicionais foram utilizados para melhorar as visualizações apresentadas no post. Para ver o código completo consulte meu [GitHub](https://github.com/viniciusoike/restateinsight).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(forecast)\nlibrary(urca)\nlibrary(qs)\n```\n:::\n\n\n\n\n# Metodologia\n\nEste post tem como objetivo principal demonstrar a aplicação prática dos modelos ARIMA em séries macroeconômicas brasileiras, explorando tanto a metodologia tradicional de Box-Jenkins quanto abordagens automatizadas mais recentes.\n\n## Box-Jenkins\n\nA metodologia Box-Jenkins parte do princípio da parcimônia. Esta abordagem iterativa é composta por três etapas fundamentais: identificação, estimação e verificação.\n\nA identificação da ordem do modelo é feita visualmente usando gráficos de autocorrelação e autocorrelação parcial.\n\nVários modelos concorrentes são estimados e escolhe-se o mais apropriado usando uma mistura de parcimônia, critérios de informação e testes estatísticos. Resumidamente,\n\n1.  Usando um teste de raiz unitária, identifica se a série é não-estacionária. Se a série for estacionária pode-se usar um modelo ARMA(p, q).\n2.  Se a série for não-estacionária, tira a primeira diferença da série e repete o processo até que a série se torne estacionária.\n3.  Avalia-se a FAC e FACP para propor um modelo de \"ordem máxima\".\n4.  Estima-se vários modelos ARIMA(p,q) de ordens menores.\n5.  Seleciona-se o melhor modelo segundo algum critério. A abordagem mais simples é escolher algum critério de informação como o BIC.\n\nAplicaremos esta metodologia completa à série de consumo das famílias brasileiras.\n\n## Macroeconomia: consumo no Brasil\n\nPara acompanhar estes exemplos vamos usar as séries das contas nacionais brasileiras. Estas séries são trimestrais e dessazonalizadas. Além disso, os seus valores são indexados, em base-100, em 1995, o primeiro ano da série completa. O código abaixo importa os dados\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmacro <- qs::qread(\"...\")\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-bordered table-hover table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> data </th>\n   <th style=\"text-align:center;\"> pib </th>\n   <th style=\"text-align:center;\"> consumo </th>\n   <th style=\"text-align:center;\"> governo </th>\n   <th style=\"text-align:center;\"> fbkf </th>\n   <th style=\"text-align:center;\"> export </th>\n   <th style=\"text-align:center;\"> import </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 1996-03-31 </td>\n   <td style=\"text-align:center;\"> 100.84 </td>\n   <td style=\"text-align:center;\"> 98.63 </td>\n   <td style=\"text-align:center;\"> 99.14 </td>\n   <td style=\"text-align:center;\"> 96.84 </td>\n   <td style=\"text-align:center;\"> 98.21 </td>\n   <td style=\"text-align:center;\"> 91.34 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 1996-07-01 </td>\n   <td style=\"text-align:center;\"> 100.36 </td>\n   <td style=\"text-align:center;\"> 100.88 </td>\n   <td style=\"text-align:center;\"> 100.74 </td>\n   <td style=\"text-align:center;\"> 98.94 </td>\n   <td style=\"text-align:center;\"> 95.94 </td>\n   <td style=\"text-align:center;\"> 99.91 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 1996-10-01 </td>\n   <td style=\"text-align:center;\"> 104.40 </td>\n   <td style=\"text-align:center;\"> 103.93 </td>\n   <td style=\"text-align:center;\"> 104.24 </td>\n   <td style=\"text-align:center;\"> 102.12 </td>\n   <td style=\"text-align:center;\"> 95.63 </td>\n   <td style=\"text-align:center;\"> 107.19 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 1996-12-31 </td>\n   <td style=\"text-align:center;\"> 103.28 </td>\n   <td style=\"text-align:center;\"> 109.17 </td>\n   <td style=\"text-align:center;\"> 88.58 </td>\n   <td style=\"text-align:center;\"> 106.81 </td>\n   <td style=\"text-align:center;\"> 100.45 </td>\n   <td style=\"text-align:center;\"> 118.61 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 1997-03-31 </td>\n   <td style=\"text-align:center;\"> 104.07 </td>\n   <td style=\"text-align:center;\"> 106.42 </td>\n   <td style=\"text-align:center;\"> 100.31 </td>\n   <td style=\"text-align:center;\"> 108.11 </td>\n   <td style=\"text-align:center;\"> 105.16 </td>\n   <td style=\"text-align:center;\"> 118.78 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 1997-07-01 </td>\n   <td style=\"text-align:center;\"> 105.10 </td>\n   <td style=\"text-align:center;\"> 106.92 </td>\n   <td style=\"text-align:center;\"> 99.91 </td>\n   <td style=\"text-align:center;\"> 109.03 </td>\n   <td style=\"text-align:center;\"> 111.29 </td>\n   <td style=\"text-align:center;\"> 123.62 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nInicialmente, vamos usar somente a série de consumo.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Série de consumo\ncons <- ts(macro$consumo, start = c(1996, 1), frequency = 4)\n```\n:::\n\n\n## 1. Estacionaridade\n\nGrosso modo, uma série estacionária possui propriedades estatísticas que não variam no tempo. Isto garante que métricas usuais como média e variância continuem fazendo sentido.\n\n::: {#box}\nPropriedades de séries estacionárias.\n\n1.  Média constante.\n2.  Variância finita e constante.\n3.  Autocovariância que depende somente do tamanho do intervalo de tempo considerado.\n:::\n\nCostuma ser fácil enxergar se uma série é estacionária ou não-estacionária. Visualmente, uma série não-estacionária cresce ou diminui ao longo do tempo; em alguns casos, ela possui períodos de oscilação (i.e. variância) mais/menos intensa.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nAlém disso, é muito mais comum encontrar séries que são não-estacionárias do que o contrário. Séries estacionárias oscilam de maneira regular em torno de uma média constante e são visualmente similares a um ruído branco. Já a maioria das séries de tempo que se encontra na prática são ou uma linha que sobe ou uma linha que desce.\n\n<div>\n\nAnálise visual:\n\n1.  Série aumenta ou diminui muito ao longo do tempo (i.e. parece ter uma tendência).\n2.  Volatailidade da série cresce ou diminui ao longo do tempo.\n\n</div>\n\nO gráfico abaixo, feito com a função `autoplot`, mostra a série de consumo dessazonalizada. Como se vê, ela apresenta claros indícios de ser não-estacionária, pois a média dela não é constante no tempo.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# echo: false\nautoplot(cons) +\n  ggtitle(\"Consumo das famílias (dessazonalizado)\") +\n  xlab(NULL) +\n  ylab(\"Index (100 = 1995)\") +\n  theme_ts\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n### Autocorrelação\n\nPode-se verificar o gráfico de autocorrelação e autocorrelação parcial da série como um critério informal para avaliar a estacionaridade[^4]. Em geral, se a FAC demora muito para decair, a série é não-estacionária. O gráfico abaixo mostra a FAC e FACP de cinco \"ciclos\" da série.\n\n[^4]: A rigor, a FAC e FACP são apenas definidas para séries estacionárias, então não faz sentido plotar a FAC de uma série não-estacionária.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggAcf(cons, lag.max = frequency(cons) * 5)\nggPacf(cons, lag.max = frequency(cons) * 5)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n### Teste de raiz unitária\n\nTestes de raiz unitária podem ser bastante complexos. Tipicamente, aplica-se um teste ADF (Augmented Dickey-Fuller) mais geral (com constante e tendência) e vai-se afunilando até o ADF mais simples (sem constante e sem tendência). Enders (1995) apresenta uma boa exposição do assunto e oferece um fluxograma de como melhor aplicar os testes.\n\nO grande problema do teste ADF é que ele tem baixo poder e queremos não-rejeitar (aceitar) a hipótese nula. O fluxograma de Enders visa minimizar o risco de se aceitar a hipótese de raiz unitária devido ao baixo poder do teste ADF. Alternativamente, pode-se usar o teste Philips-Perron (`ur.pp`).\n\nAbaixo mostro como fazer o teste ADF, nas suas três versões, usando o critério BIC para seleção automática do número de defasagens. Neste caso, fica claro que a série possui uma ruiz unitária sem constante e sem tendência. A rigor, seria necessário aplicar os mesmos testes sobre a primeira diferença da série para verificar se há somente uma raiz unitária.\n\nOs resultados podem ser melhor detalhados usando `summary` , i.e., `summary(adf1)`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nur.df(cons, type = \"trend\", lags = 12, selectlags = \"BIC\")\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nadf1 = ur.df(cons, type = \"trend\", lags = 12, selectlags = \"BIC\")\nadf2 = ur.df(cons, type = \"drift\", lags = 12, selectlags = \"BIC\")\nadf3 = ur.df(cons, type = \"none\", lags = 12, selectlags = \"BIC\")\n```\n:::\n\n\n# 2. Identificação\n\nA etapa de identificação constitui o ponto de partida da metodologia Box-Jenkins, onde determinamos a estrutura mais apropriada do modelo ARIMA(p,d,q) através de análise gráfica.\n\n## Train e test\n\nUma prática comum em séries de tempo é remover um percentual das observações finais afim de testar a capacidade preditiva do modelo[^5]. Esta abordagem também é bastente comum na literatura de Machine Learning, onde o objetivo costuma ser gerar previsões.\n\n[^5]: Caso seu interesse seja encontrar o melhor ajuste aos dados, pode fazer sentido usar a série inteira e não remover observações.\n\nO código abaixo cria uma série `train` com cerca de 85% das observações. Vale notar que há maneiras mais sofisticadas de fazer esta divisão e veremos como fazer uma delas mais adiante.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\na = 0.15\nh = floor(a * length(cons))\ntrain = head(cons, length(cons) - h)\ntest = tail(cons, h)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Autocorrelação\n\nO gráfico abaixo mostra a FAC e FACP da primeira diferença. Agora, temos somente a primeira defasagem significativa em cada um dos gráficos. Assim, podemos supor que o modelo de ordem máximo é um ARIMA (1, 1, 1).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndcons <- diff(train)\n\nggAcf(train)\nggPacf(train)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n# 3. Estimação\n\nVamos estimar quatro modelos: ARIMA(1, 1, 1), ARIMA (1, 1, 0), ARIMA (0, 1, 1) e ARIMA (0, 1, 0). A interpretação dos coeficientes requer cuidado especial:\n\n-   **Coeficiente AR(1)**: mede a persistência da série; valores próximos a 1 indicam alta persistência.\n\n-   **Coeficiente MA(1)**: captura o efeito de choques aleatórios passados sobre o valor atual.\n\n-   **Significância estatística**: avaliada através de testes t individuais.\n\nVale notar que algumas estatísticas comuns como o R² ou R² ajustado não fazem sentido nos modelos ARMA e ARIMA devido às características assintóticas dos estimadores. Até por isso, é comum omitir ambos.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm1 = Arima(train, order = c(0, 1, 0), include.drift = TRUE)\nm2 = Arima(train, order = c(1, 1, 1))\nm3 = Arima(train, order = c(1, 1, 0))\nm4 = Arima(train, order = c(0, 1, 1))\n```\n:::\n\n\nA saída do modelo ARIMA (1, 1, 1) indica a estimativa dos coeficientes junto com a estimativa da variância do erro e o cálculo dos critérios de informação. O modelo estimado tem a forma:\n\n$$\n\\Delta y_{t} = 0.9449 \\Delta y_{t-1} - 0.7277 \\varepsilon_{t-1}\n$$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: train \nARIMA(1,1,1) \n\nCoefficients:\n         ar1      ma1\n      0.9469  -0.7277\ns.e.  0.0490   0.1162\n\nsigma^2 = 2.907:  log likelihood = -153.58\nAIC=313.17   AICc=313.49   BIC=320.28\n```\n\n\n:::\n:::\n\n\n# 4. Diagnóstico de resíduos\n\nPara verificar o ajuste do modelo aos dados fazemos um diagnóstico sobre seus resíduos. Idealmente, os resíduos \\$e\\_{t} = y\\_{t} - \\hat{y_{t}}\\$ ou os resíduos normalizados devem se comportar como ruído branco. Os resíduos normalizados são definidos como:\n\n$$\ne_{t} = \\frac{y_{t} - \\hat{y_{t}}}{\\sqrt{\\sigma^2}}\n$$\n\nonde $\\sigma^2$ é o valor estimado da variância dos resíduos. A distribuição de $e_{t}$ deve ser i.i.d. com média zero e variância unitária.\n\nQueremos verificar as seguintes propriedades nos resíduos:\n\n-   Ausência de autocorrelação.\n-   Média igual a zero.\n-   Variância constante (homocedasticidade).\n-   Normalidade.\n\nEm termos de previsão, o mais importante é verificar se a média do resíduo é zero. Qualquer valor diferente de zero indica que a previsão do modelo será enviesada. Em termos econométricos, o mais importante é verificar a ausência de autocorrelação. A hipótese de homocedasticidade é importante\n\nPara selecionar os resíduos de um modelo usa-se `residuals`. O valor de $\\sigma^2$ já foi calculado pela função `Arima` então precisamos somente selecionar o valor.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nu1 = residuals(m1) / sqrt(m1$sigma2)\nu2 = residuals(m2) / sqrt(m2$sigma2)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np1 <- autoplot(u1) + labs(subtitle = \"ARIMA (0, 1, 0)\")\np2 <- autoplot(u2) + labs(subtitle = \"ARIMA (1, 1, 1)\")\npanel <- p1 / p2\n\npanel & plot_annotation(\n  title = \"Resíduo dos modelos ARIMA (0, 1, 0) e ARIMA (1, 1, 1)\"\n) &\n  theme_ts +\n  theme(axis.title = element_blank())\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nNovamente, faz-se uma verificação tanto visual como estatística.\n\n## Autocorrelação serial\n\nVisualmente, temos duas opções para verificar a autocorrelação serial nos resíduos: a FAC e um lag plot.\n\nDa mesma forma como fizemos antes, podemos fazer a FAC da série. Nota-se que a primeira defasagem é significativa (i.e. não é zero). Já a FAC do modelo ARIMA (1, 1, 1) não apresenta termos significativos, sugerindo que o resíduo não apresenta autocorrelação.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggAcf(u1, lag.max = 20)\nggAcf(u2, lag.max = 20)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nAlternativamente, podemos fazer um gráfico de defasagens (lag plot). Em cada um dos quadrantes abaixo o resíduo é plotado contra seu valor defasado. Se não houver autocorrelação, os gráficos devem ser nuvens \"aleatórias\" de pontos.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngglagplot(u1, do.lines = FALSE, colour = FALSE, lags = 4) + theme_ts\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngglagplot(u2, do.lines = FALSE, colour = FALSE, lags = 4) + theme_ts\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-24-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Testes Estatísticos\n\nFormalmente, há pelo menos duas opções para testar a presença de autocorrelação: o teste Ljung-Box (ou Portmanteau) e o teste Breusch-Godfrey (BG test). O primeiro é o mais comum e o código abaixo mostra como calculá-lo.\n\n### Ljung-Box\n\nNote que, neste caso `fitdf = 0` pois não estimamos termos p e q no modelo ARIMA. A hipótese nula do teste Ljung-Box é de que a autocorrelação conjunta até defasagem k é igual a zero. Neste sentido, queremos não-rejeitar (aceitar) a hipótese nula.\n\nNo caso abaixo, vemos que o p-valor do teste com oito defasagens é pequeno e menor que 0.05, indicando que há alguma autocorrelação no resíduo do modelo.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nBox.test(u1, type = \"Ljung-Box\", fitdf = 0, lag = 8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBox-Ljung test\n\ndata:  u1\nX-squared = 16.311, df = 8, p-value = 0.03814\n```\n\n\n:::\n:::\n\n\nPode ser interessante testar vários valores diferentes no teste Ljung-Box. O código abaixo mostra como fazer um loop simples para calcular vários valores desta estatística.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlags = c(1, 4, 8, 12, 16, 20, 24)\ntabela = matrix(nrow = length(lags), ncol = 3)\n\nfor (i in seq_along(lags)) {\n  \n  lag = lags[[i]]\n  test = Box.test(u1, type = \"Ljung-Box\", fitdf = 0, lag = lag)\n\ttabela[i, ] = c(lag, as.numeric(test$statistic), as.numeric(test$p.value))\n}\n```\n:::\n\n\nA tabela abaixo mostra o resultado do teste Ljung-Box para diversas defasagens.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-hover table-bordered table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Resultados do teste Ljung-Box sobre os resíduos do modelo</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Lag </th>\n   <th style=\"text-align:center;\"> Estatística </th>\n   <th style=\"text-align:center;\"> P-valor </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 7.53578 </td>\n   <td style=\"text-align:center;\"> 0.00605 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4 </td>\n   <td style=\"text-align:center;\"> 11.46158 </td>\n   <td style=\"text-align:center;\"> 0.02184 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 8 </td>\n   <td style=\"text-align:center;\"> 16.31102 </td>\n   <td style=\"text-align:center;\"> 0.03814 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 12 </td>\n   <td style=\"text-align:center;\"> 17.96947 </td>\n   <td style=\"text-align:center;\"> 0.11662 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 16 </td>\n   <td style=\"text-align:center;\"> 21.18401 </td>\n   <td style=\"text-align:center;\"> 0.17155 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 20 </td>\n   <td style=\"text-align:center;\"> 24.20865 </td>\n   <td style=\"text-align:center;\"> 0.23340 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 24 </td>\n   <td style=\"text-align:center;\"> 30.11548 </td>\n   <td style=\"text-align:center;\"> 0.18095 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Breusch-Godfrey\n\nO teste Breusch-Godfrey é, essencialmente, uma regressão linear do resíudo contra seus valores defasados. Na sua forma mais simples o teste é dado como:\n\n$$\n\\hat{u}_{t} = \\alpha + \\rho_{1}\\hat{u}_{t-1} + \\rho_{2}\\hat{u}_{t-2} + \\dots + \\rho_{p}\\hat{u}_{t-p} + v_{t}\n$$\n\nonde $\\hat{u}_{t-1}$ é o valor estimado do resíduo, $\\alpha$ é uma constante, $\\rho_{i}$ é um coeficiente que mede a autocorrelação entre o resíduo e a sua i-ésima defasagem e $v_{t}$ é um termo de erro. Intuitivamente, queremos que todos os valores de $\\rho_{i}$ sejam iguais a zero pois o resíduo não deve ter uma relação linear com seus valores defasados.\n\nInfelizmente, a função `lmtest::bgtest` foi feita para funcionar com o output de modelos de regressão linear criados com a a função `lm`. Assim, a função não funciona diretamente com um output de `Arima()` e é preciso montar a regressão manualmente, o que pode ser um pouco chato.\n\nNo código abaixo uso a função `ts.union` para reunir todas as séries (funciona como um `full_join`). A função `lmtest::bgtest` aceita uma sintaxe de `formula` similar a da função `lm` do tipo `y ~ x1 + x2`.\n\nA hipótese nula do teste é de que $\\rho_{i} = 0$, ou seja, novamente queremos não-rejeitar a hipótese nula. Como se abaixo, em ambos os casos temos evidência de autocorrelação.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Monta um data.frame com o resíduo e suas defasagens\nudata <- ts.union(\n  u = u1,\n  ul1 = lag(u1, -1),\n  ul2 = lag(u1, -2),\n  ul3 = lag(u1, -3),\n  ul4 = lag(u1, -4),\n  dframe = TRUE\n  )\n# Roda o BG test com uma defasagem\nlmtest::bgtest(u ~ 1 + ul1, data = udata, fill = NA, type = \"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBreusch-Godfrey test for serial correlation of order up to 1\n\ndata:  u ~ 1 + ul1\nLM test = 0.44503, df1 = 1, df2 = 75, p-value = 0.5068\n```\n\n\n:::\n\n```{.r .cell-code}\n# Roda o BG test com quatro defasagens\nlmtest::bgtest(u ~ 1 + ul1 + ul2 + ul3 + ul4, data = udata, fill = NA, type = \"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBreusch-Godfrey test for serial correlation of order up to 1\n\ndata:  u ~ 1 + ul1 + ul2 + ul3 + ul4\nLM test = 3.2901, df1 = 1, df2 = 69, p-value = 0.07405\n```\n\n\n:::\n:::\n\n\n## Heterocedasticidade\n\nA maneira mais simples de verificar heterocedasticidade é procurar pela presença de picos na série do quadrado do resíduo. O gráfico abaixo mostra os dois gráficos lado a lado. Vê-se que há picos de volatilidade em ambos os resíduos.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(u1^2)\nautoplot(u2^2)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np1 = autoplot(u1^2) + \n  labs(\n    subtitle = \"Quadrado dos resíduos do modelo ARIMA (0, 1, 0)\",\n    x = NULL,\n    y = latex2exp::TeX(\"$u_{t}^2$\"))\n\np2 = autoplot(u2^2) + \n  labs(\n    subtitle = \"Quadrado dos resíduos do modelo ARIMA (1, 1, 1)\",\n    x = NULL,\n    y = latex2exp::TeX(\"$u_{t}^2$\"))\n\n(p1 | p2) + plot_annotation(\n  title = \"Verificando homocedasticidade\",\n  subtitle = \"Picos na série do quadrado dos resíduos indicam a presença de heterocedasticidade.\"\n) &\n  theme_ts\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-30-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n### Arch test\n\nO test ARCH (autoregressive conditional heteroskedasticity**)** é, conceitualmente, muito similar ao teste Breusch-Godfrey, visto anteriormente. A ideia é fazer uma regressão do quadrado do resíduo contra seus valores defasados para verificar a presença de alguma\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nFinTS::ArchTest(u1, lags = 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tARCH LM-test; Null hypothesis: no ARCH effects\n\ndata:  u1\nChi-squared = 11.216, df = 4, p-value = 0.02424\n```\n\n\n:::\n:::\n\n\n## Normalidade dos resíduos\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntseries::jarque.bera.test(u1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tJarque Bera Test\n\ndata:  u1\nX-squared = 4.8301, df = 2, p-value = 0.08936\n```\n\n\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncheckresiduals(m1) + theme_ts\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-33-1.png){fig-align='center' width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tLjung-Box test\n\ndata:  Residuals from ARIMA(0,1,0) with drift\nQ* = 16.311, df = 8, p-value = 0.03814\n\nModel df: 0.   Total lags used: 8\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}