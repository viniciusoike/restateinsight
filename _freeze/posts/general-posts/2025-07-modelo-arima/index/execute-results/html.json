{
  "hash": "7a579c9954b6122cd889bcb49ef06354",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Modelo ARIMA no R\"\ndate: \"2025-07-01\"\ncategories: ['data-science', 'time-series', 'econometria']\ndescription: \"Demonstração prática da aplicação de modelos ARIMA em séries macroeconômicas brasileiras usando a metodologia Box-Jenkins, desde a identificação da ordem do modelo até a previsão de valores futuros.\"\nformat: html\nexecute:\n  warning: false\n  message: false\n\n---\n\n\n\n# O modelo\n\nA teoria dos [modelos ARMA(p,q)](https://restateinsight.com/posts/general-posts/repost-arma-exemplo-simples/) serve apenas para séries estiacionárias; na prática, contudo, é bastante frequente encontrar séries não-estacionárias. Séries com tendência de crescimento ou cuja variância aumenta ao longo do tempo são exemplos típicos de não-estacionaridade que encontra-se nos dados.\n\nA ideia da modelagem ARIMA é de tirar diferenças na série original de forma a torná-la estacionária. Isto é, se tivermos uma série $y_{t}$ que não é estacionária, vamos transformá-la em $x_{t} \\equiv y_{t} - y_{t-1}$ para torná-la estacionária.\n\nNeste caso, a série $x_{t}$ é chamada a primeira diferença de $y_{t}$. Eventualmente será necessário tirar mais do que uma diferença para tornar a série estacionária.\n\n## Contexto\n\nA análise de séries temporais ocupa um lugar central na macroeconomia moderna, fornecendo ferramentas essenciais para compreender a dinâmica das principais variáveis econômicas. Os modelos ARIMA (AutoRegressive Integrated Moving Average) representam uma das abordagens mais consolidadas e amplamente utilizadas para modelagem de séries temporais univariadas.\n\nO ARIMA combina simplicidade e boa capacidade preditiva. Neste sentido, ele serve tanto como uma ferramenta central, dentro de uma análise macroeconômica, como também como benchmark para modelos mais sofisticados.\n\n### R\n\nA modelagem de séries temporais no `R` é um tanto caótica. Isto acontece pela diversidade e complexidade de dados em séries de tempo. Via de regra, as funções-base do `R` servem muito bem para séries mensais, trimestrais e anuais. Quando se lida, por exemplo, com dados financeiros diários ou intra-diários costuma ser necessário usar pacotes especializados.\n\nCom o tempo, as funções base do `R` se tornaram um tanto defasadas. Os gráficos do `R` foram revolucionados pelo pacote `ggplot2` mas a sua sintaxe não funciona tão diretamente com séries de tempo; como resultado, alguns ajustes são necessários para compatibilizar os dois.\n\nNeste post, tentei manter o código o mais simples possível usando somente o pacote `forecast`[^1], que é excelente para o tratamento de séries de tempo univariadas[^2]. Abaixo segue a lista dos pacotes necessários para acompanhar este post[^3].\n\n[^1]: Para mais sobre o pacote `forecast` vale consultar o livro [Forecasting: Principles and Practice](https://otexts.com/fpp2/).\n\n[^2]: O pacote `forecast` começa a ficar um pouco limitado quando se lida com muitas séries de tempo (e.g. mais de 20).\n\n[^3]: Alguns pacotes adicionais foram utilizados para melhorar as visualizações apresentadas no post. Para ver o código completo consulte meu [GitHub](https://github.com/viniciusoike/restateinsight).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(forecast)\nlibrary(urca)\nlibrary(qs)\n```\n:::\n\n\n\n\n# Metodologia\n\nEste post tem como objetivo principal demonstrar a aplicação prática dos modelos ARIMA em séries macroeconômicas brasileiras, explorando tanto a metodologia tradicional de Box-Jenkins quanto abordagens automatizadas mais recentes.\n\n## Box-Jenkins\n\nA metodologia Box-Jenkins parte do princípio da parcimônia. Esta abordagem iterativa é composta por três etapas fundamentais: identificação, estimação e verificação.\n\nA identificação da ordem do modelo é feita visualmente usando gráficos de autocorrelação e autocorrelação parcial.\n\nVários modelos concorrentes são estimados e escolhe-se o mais apropriado usando uma mistura de parcimônia, critérios de informação e testes estatísticos. Resumidamente,\n\n1.  Usando um teste de raiz unitária, identifica se a série é não-estacionária. Se a série for estacionária pode-se usar um modelo ARMA(p, q).\n2.  Se a série for não-estacionária, tira a primeira diferença da série e repete o processo até que a série se torne estacionária.\n3.  Avalia-se a FAC e FACP para propor um modelo de \"ordem máxima\".\n4.  Estima-se vários modelos ARIMA(p,q) de ordens menores.\n5.  Seleciona-se o melhor modelo segundo algum critério. A abordagem mais simples é escolher algum critério de informação como o BIC.\n\nAplicaremos esta metodologia completa à série de consumo das famílias brasileiras.\n\n## Macroeconomia: consumo no Brasil\n\nPara acompanhar estes exemplos vamos usar as séries das contas nacionais brasileiras. Estas séries são trimestrais e dessazonalizadas. Além disso, os seus valores são indexados, em base-100, em 1995, o primeiro ano da série completa.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-bordered table-hover table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> data </th>\n   <th style=\"text-align:center;\"> pib </th>\n   <th style=\"text-align:center;\"> consumo </th>\n   <th style=\"text-align:center;\"> governo </th>\n   <th style=\"text-align:center;\"> fbkf </th>\n   <th style=\"text-align:center;\"> export </th>\n   <th style=\"text-align:center;\"> import </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 1996-03-31 </td>\n   <td style=\"text-align:center;\"> 100.84 </td>\n   <td style=\"text-align:center;\"> 98.63 </td>\n   <td style=\"text-align:center;\"> 99.14 </td>\n   <td style=\"text-align:center;\"> 96.84 </td>\n   <td style=\"text-align:center;\"> 98.21 </td>\n   <td style=\"text-align:center;\"> 91.34 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 1996-07-01 </td>\n   <td style=\"text-align:center;\"> 100.36 </td>\n   <td style=\"text-align:center;\"> 100.88 </td>\n   <td style=\"text-align:center;\"> 100.74 </td>\n   <td style=\"text-align:center;\"> 98.94 </td>\n   <td style=\"text-align:center;\"> 95.94 </td>\n   <td style=\"text-align:center;\"> 99.91 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 1996-10-01 </td>\n   <td style=\"text-align:center;\"> 104.40 </td>\n   <td style=\"text-align:center;\"> 103.93 </td>\n   <td style=\"text-align:center;\"> 104.24 </td>\n   <td style=\"text-align:center;\"> 102.12 </td>\n   <td style=\"text-align:center;\"> 95.63 </td>\n   <td style=\"text-align:center;\"> 107.19 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 1996-12-31 </td>\n   <td style=\"text-align:center;\"> 103.28 </td>\n   <td style=\"text-align:center;\"> 109.17 </td>\n   <td style=\"text-align:center;\"> 88.58 </td>\n   <td style=\"text-align:center;\"> 106.81 </td>\n   <td style=\"text-align:center;\"> 100.45 </td>\n   <td style=\"text-align:center;\"> 118.61 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 1997-03-31 </td>\n   <td style=\"text-align:center;\"> 104.07 </td>\n   <td style=\"text-align:center;\"> 106.42 </td>\n   <td style=\"text-align:center;\"> 100.31 </td>\n   <td style=\"text-align:center;\"> 108.11 </td>\n   <td style=\"text-align:center;\"> 105.16 </td>\n   <td style=\"text-align:center;\"> 118.78 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 1997-07-01 </td>\n   <td style=\"text-align:center;\"> 105.10 </td>\n   <td style=\"text-align:center;\"> 106.92 </td>\n   <td style=\"text-align:center;\"> 99.91 </td>\n   <td style=\"text-align:center;\"> 109.03 </td>\n   <td style=\"text-align:center;\"> 111.29 </td>\n   <td style=\"text-align:center;\"> 123.62 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nInicialmente, vamos usar somente a série de consumo.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Série de consumo\ncons = ts(macro$consumo, start = c(1996, 1), frequency = 4)\n```\n:::\n\n\n## 1. Estacionaridade\n\nGrosso modo, uma série estacionária possui propriedades estatísticas que não variam no tempo. Isto garante que métricas usuais como média e variância continuem fazendo sentido.\n\n::: {#box}\nPropriedades de séries estacionárias.\n\n1.  Média constante.\n2.  Variância finita e constante.\n3.  Autocovariância que depende somente do tamanho do intervalo de tempo considerado.\n:::\n\nCostuma ser fácil enxergar se uma série é estacionária ou não-estacionária. Visualmente, uma série não-estacionária cresce ou diminui ao longo do tempo; em alguns casos, ela possui períodos de oscilação (i.e. variância) mais/menos intensa.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nAlém disso, é muito mais comum encontrar séries que são não-estacionárias do que o contrário. Séries estacionárias oscilam de maneira regular em torno de uma média constante e são visualmente similares a um ruído branco. Já a maioria das séries de tempo que se encontra na prática são ou uma linha que sobe ou uma linha que desce.\n\n<div>\n\nAnálise visual:\n\n1.  Série aumenta ou diminui muito ao longo do tempo (i.e. parece ter uma tendência).\n2.  Volatailidade da série cresce ou diminui ao longo do tempo.\n\n</div>\n\nO gráfico abaixo, feito com a função `autoplot`, mostra a série de consumo dessazonalizada. Como se vê, ela apresenta claros indícios de ser não-estacionária, pois a média dela não é constante no tempo.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# echo: false\nautoplot(cons) +\n  ggtitle(\"Consumo das famílias (dessazonalizado)\") +\n  xlab(NULL) +\n  ylab(\"Index (100 = 1995)\") +\n  theme_ts\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n### Autocorrelação\n\nPode-se verificar o gráfico de autocorrelação e autocorrelação parcial da série como um critério informal para avaliar a estacionaridade[^4]. Em geral, se a FAC demora muito para decair, a série é não-estacionária. O gráfico abaixo mostra a FAC e FACP de cinco \"ciclos\" da série.\n\n[^4]: A rigor, a FAC e FACP são apenas definidas para séries estacionárias, então não faz sentido plotar a FAC de uma série não-estacionária.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggAcf(cons, lag.max = frequency(cons) * 5)\nggPacf(cons, lag.max = frequency(cons) * 5)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n### Teste de raiz unitária\n\nTestes de raiz unitária podem ser bastante complexos. Tipicamente, aplica-se um teste ADF (Augmented Dickey-Fuller) mais geral (com constante e tendência) e vai-se afunilando até o ADF mais simples (sem constante e sem tendência). Enders (1995) apresenta uma boa exposição do assunto e oferece um fluxograma de como melhor aplicar os testes.\n\nO grande problema do teste ADF é que ele tem baixo poder e queremos não-rejeitar (aceitar) a hipótese nula. O fluxograma de Enders visa minimizar o risco de se aceitar a hipótese de raiz unitária devido ao baixo poder do teste ADF. Alternativamente, pode-se usar o teste Philips-Perron (`ur.pp`).\n\nAbaixo mostro como fazer o teste ADF, nas suas três versões, usando o critério BIC para seleção automática do número de defasagens. Neste caso, fica claro que a série possui uma ruiz unitária sem constante e sem tendência. A rigor, seria necessário aplicar os mesmos testes sobre a primeira diferença da série para verificar se há somente uma raiz unitária.\n\nOs resultados podem ser melhor detalhados usando `summary` , i.e., `summary(adf1)`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nur.df(cons, type = \"trend\", lags = 12, selectlags = \"BIC\")\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nadf1 = ur.df(cons, type = \"trend\", lags = 12, selectlags = \"BIC\")\nadf2 = ur.df(cons, type = \"drift\", lags = 12, selectlags = \"BIC\")\nadf3 = ur.df(cons, type = \"none\", lags = 12, selectlags = \"BIC\")\n```\n:::\n\n\n# 2. Identificação\n\nA etapa de identificação constitui o ponto de partida da metodologia Box-Jenkins, onde determinamos a estrutura mais apropriada do modelo ARIMA(p,d,q) através de análise gráfica.\n\n## Train e test\n\nUma prática comum em séries de tempo é remover um percentual das observações finais afim de testar a capacidade preditiva do modelo[^5]. Esta abordagem também é bastente comum na literatura de Machine Learning, onde o objetivo costuma ser gerar previsões.\n\n[^5]: Caso seu interesse seja encontrar o melhor ajuste aos dados, pode fazer sentido usar a série inteira e não remover observações.\n\nO código abaixo cria uma série `train` com cerca de 85% das observações. Vale notar que há maneiras mais sofisticadas de fazer esta divisão e veremos como fazer uma delas mais adiante.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\na = 0.15\nh = floor(a * length(cons))\ntrain = head(cons, length(cons) - h)\ntest = tail(cons, h)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Autocorrelação\n\nO gráfico abaixo mostra a FAC e FACP da primeira diferença. Agora, temos somente a primeira defasagem significativa em cada um dos gráficos. Assim, podemos supor que o modelo de ordem máximo é um ARIMA (1, 1, 1).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndcons = diff(train)\n\nggAcf(train)\nggPacf(train)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n# 3. Estimação\n\nVamos estimar quatro modelos: ARIMA(1, 1, 1), ARIMA (1, 1, 0), ARIMA (0, 1, 1) e ARIMA (0, 1, 0). A interpretação dos coeficientes requer cuidado especial:\n\n-   **Coeficiente AR(1)**: mede a persistência da série; valores próximos a 1 indicam alta persistência.\n\n-   **Coeficiente MA(1)**: captura o efeito de choques aleatórios passados sobre o valor atual.\n\n-   **Significância estatística**: avaliada através de testes t individuais.\n\nVale notar que algumas estatísticas comuns como o R² ou R² ajustado não fazem sentido nos modelos ARMA e ARIMA devido às características assintóticas dos estimadores. Até por isso, é comum omitir ambos.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm1 = Arima(train, order = c(0, 1, 0), include.drift = TRUE)\nm2 = Arima(train, order = c(1, 1, 1))\nm3 = Arima(train, order = c(1, 1, 0))\nm4 = Arima(train, order = c(0, 1, 1))\nm5 = Arima(train, order = c(1, 1, 1), include.drift = TRUE)\n```\n:::\n\n\nA saída do modelo ARIMA (1, 1, 1) indica a estimativa dos coeficientes junto com a estimativa da variância do erro e o cálculo dos critérios de informação. O modelo estimado tem a forma:\n\n$$\n\\Delta y_{t} = 0.9449 \\Delta y_{t-1} - 0.7277 \\varepsilon_{t-1}\n$$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: train \nARIMA(1,1,1) \n\nCoefficients:\n         ar1      ma1\n      0.9469  -0.7277\ns.e.  0.0490   0.1162\n\nsigma^2 = 2.907:  log likelihood = -153.58\nAIC=313.17   AICc=313.49   BIC=320.28\n```\n\n\n:::\n:::\n\n\n# 4. Diagnóstico de resíduos\n\nPara verificar o ajuste do modelo aos dados fazemos um diagnóstico sobre seus resíduos. Idealmente, os resíduos \\$e\\_{t} = y\\_{t} - \\hat{y_{t}}\\$ ou os resíduos normalizados devem se comportar como ruído branco. Os resíduos normalizados são definidos como:\n\n$$\ne_{t} = \\frac{y_{t} - \\hat{y_{t}}}{\\sqrt{\\sigma^2}}\n$$\n\nonde $\\sigma^2$ é o valor estimado da variância dos resíduos. A distribuição de $e_{t}$ deve ser i.i.d. com média zero e variância unitária.\n\nQueremos verificar as seguintes propriedades nos resíduos:\n\n-   Ausência de autocorrelação.\n-   Média igual a zero.\n-   Variância constante (homocedasticidade).\n-   Normalidade.\n\nEm termos de previsão, o mais importante é verificar se a média do resíduo é zero. Qualquer valor diferente de zero indica que a previsão do modelo será enviesada. Em termos econométricos, o mais importante é verificar a ausência de autocorrelação. A hipótese de homocedasticidade é importante para a validade dos intervalos de confiança das previsões, embora violações moderadas costumem ser toleradas na prática\n\nPara selecionar os resíduos de um modelo usa-se `residuals`. O valor de $\\sigma^2$ já foi calculado pela função `Arima` então precisamos somente selecionar o valor.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nu1 = residuals(m1) / sqrt(m1$sigma2)\nu2 = residuals(m2) / sqrt(m2$sigma2)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np1 = autoplot(u1) + labs(subtitle = \"ARIMA (0, 1, 0)\")\np2 = autoplot(u2) + labs(subtitle = \"ARIMA (1, 1, 1)\")\npanel = p1 / p2\n\npanel &\n  plot_annotation(\n    title = \"Resíduo dos modelos ARIMA (0, 1, 0) e ARIMA (1, 1, 1)\"\n  ) &\n  theme_ts +\n    theme(axis.title = element_blank())\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nNovamente, faz-se uma verificação tanto visual como estatística.\n\n## Autocorrelação serial\n\nVisualmente, temos duas opções para verificar a autocorrelação serial nos resíduos: a FAC e um lag plot.\n\nDa mesma forma como fizemos antes, podemos fazer a FAC da série. Nota-se que a primeira defasagem é significativa (i.e. não é zero). Já a FAC do modelo ARIMA (1, 1, 1) não apresenta termos significativos, sugerindo que o resíduo não apresenta autocorrelação.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggAcf(u1, lag.max = 20)\nggAcf(u2, lag.max = 20)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nAlternativamente, podemos fazer um gráfico de defasagens (lag plot). Em cada um dos quadrantes abaixo o resíduo é plotado contra seu valor defasado. Se não houver autocorrelação, os gráficos devem ser nuvens \"aleatórias\" de pontos.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngglagplot(u1, do.lines = FALSE, colour = FALSE, lags = 4) + theme_ts\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngglagplot(u2, do.lines = FALSE, colour = FALSE, lags = 4) + theme_ts\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Testes Estatísticos\n\nFormalmente, há pelo menos duas opções para testar a presença de autocorrelação: o teste Ljung-Box (ou Portmanteau) e o teste Breusch-Godfrey (BG test). O primeiro é o mais comum e o código abaixo mostra como calculá-lo.\n\n### Ljung-Box\n\nNote que, neste caso `fitdf = 0` pois não estimamos termos p e q no modelo ARIMA. A hipótese nula do teste Ljung-Box é de que a autocorrelação conjunta até defasagem k é igual a zero. Neste sentido, queremos não-rejeitar (aceitar) a hipótese nula.\n\nNo caso abaixo, vemos que o p-valor do teste com oito defasagens é pequeno e menor que 0.05, indicando que há alguma autocorrelação no resíduo do modelo.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nBox.test(u1, type = \"Ljung-Box\", fitdf = 0, lag = 8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBox-Ljung test\n\ndata:  u1\nX-squared = 16.311, df = 8, p-value = 0.03814\n```\n\n\n:::\n:::\n\n\nPode ser interessante testar vários valores diferentes no teste Ljung-Box. O código abaixo mostra como fazer um loop simples para calcular vários valores desta estatística.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlags = c(1, 4, 8, 12, 16, 20, 24)\ntabela = matrix(nrow = length(lags), ncol = 3)\n\nfor (i in seq_along(lags)) {\n  lag = lags[[i]]\n  lbtest = Box.test(u1, type = \"Ljung-Box\", fitdf = 0, lag = lag)\n  tabela[i, ] = c(lag, as.numeric(lbtest$statistic), as.numeric(lbtest$p.value))\n}\n```\n:::\n\n\nA tabela abaixo mostra o resultado do teste Ljung-Box para diversas defasagens.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-hover table-bordered table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Resultados do teste Ljung-Box sobre os resíduos do modelo</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Lag </th>\n   <th style=\"text-align:center;\"> Estatística </th>\n   <th style=\"text-align:center;\"> P-valor </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 7.53578 </td>\n   <td style=\"text-align:center;\"> 0.00605 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4 </td>\n   <td style=\"text-align:center;\"> 11.46158 </td>\n   <td style=\"text-align:center;\"> 0.02184 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 8 </td>\n   <td style=\"text-align:center;\"> 16.31102 </td>\n   <td style=\"text-align:center;\"> 0.03814 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 12 </td>\n   <td style=\"text-align:center;\"> 17.96947 </td>\n   <td style=\"text-align:center;\"> 0.11662 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 16 </td>\n   <td style=\"text-align:center;\"> 21.18401 </td>\n   <td style=\"text-align:center;\"> 0.17155 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 20 </td>\n   <td style=\"text-align:center;\"> 24.20865 </td>\n   <td style=\"text-align:center;\"> 0.23340 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 24 </td>\n   <td style=\"text-align:center;\"> 30.11548 </td>\n   <td style=\"text-align:center;\"> 0.18095 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Breusch-Godfrey\n\nO teste Breusch-Godfrey é, essencialmente, uma regressão linear do resíudo contra seus valores defasados. Na sua forma mais simples o teste é dado como:\n\n$$\n\\hat{u}_{t} = \\alpha + \\rho_{1}\\hat{u}_{t-1} + \\rho_{2}\\hat{u}_{t-2} + \\dots + \\rho_{p}\\hat{u}_{t-p} + v_{t}\n$$\n\nonde $\\hat{u}_{t-1}$ é o valor estimado do resíduo, $\\alpha$ é uma constante, $\\rho_{i}$ é um coeficiente que mede a autocorrelação entre o resíduo e a sua i-ésima defasagem e $v_{t}$ é um termo de erro. Intuitivamente, queremos que todos os valores de $\\rho_{i}$ sejam iguais a zero pois o resíduo não deve ter uma relação linear com seus valores defasados.\n\nInfelizmente, a função `lmtest::bgtest` foi feita para funcionar com o output de modelos de regressão linear criados com a a função `lm`. Assim, a função não funciona diretamente com um output de `Arima()` e é preciso montar a regressão manualmente, o que pode ser um pouco chato.\n\nNo código abaixo uso a função `ts.union` para reunir todas as séries (funciona como um `full_join`). A função `lmtest::bgtest` aceita uma sintaxe de `formula` similar a da função `lm` do tipo `y ~ x1 + x2`.\n\nA hipótese nula do teste é de que $\\rho_{i} = 0$, ou seja, novamente queremos não-rejeitar a hipótese nula. Como se abaixo, em ambos os casos temos evidência de autocorrelação.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Monta um data.frame com o resíduo e suas defasagens\nudata = ts.union(\n  u = u1,\n  ul1 = lag(u1, -1),\n  ul2 = lag(u1, -2),\n  ul3 = lag(u1, -3),\n  ul4 = lag(u1, -4),\n  dframe = TRUE\n)\n# Roda o BG test com uma defasagem\nlmtest::bgtest(u ~ 1 + ul1, data = udata, fill = NA, type = \"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBreusch-Godfrey test for serial correlation of order up to 1\n\ndata:  u ~ 1 + ul1\nLM test = 0.44503, df1 = 1, df2 = 75, p-value = 0.5068\n```\n\n\n:::\n\n```{.r .cell-code}\n# Roda o BG test com quatro defasagens\nlmtest::bgtest(\n  u ~ 1 + ul1 + ul2 + ul3 + ul4,\n  data = udata,\n  fill = NA,\n  type = \"F\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBreusch-Godfrey test for serial correlation of order up to 1\n\ndata:  u ~ 1 + ul1 + ul2 + ul3 + ul4\nLM test = 3.2901, df1 = 1, df2 = 69, p-value = 0.07405\n```\n\n\n:::\n:::\n\n\n## Heterocedasticidade\n\nA maneira mais simples de verificar heterocedasticidade é procurar pela presença de picos na série do quadrado do resíduo. O gráfico abaixo mostra os dois gráficos lado a lado. Vê-se que há picos de volatilidade em ambos os resíduos.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(u1^2)\nautoplot(u2^2)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np1 = autoplot(u1^2) +\n  labs(\n    subtitle = \"Quadrado dos resíduos do modelo ARIMA (0, 1, 0)\",\n    x = NULL,\n    y = latex2exp::TeX(\"$u_{t}^2$\")\n  )\n\np2 = autoplot(u2^2) +\n  labs(\n    subtitle = \"Quadrado dos resíduos do modelo ARIMA (1, 1, 1)\",\n    x = NULL,\n    y = latex2exp::TeX(\"$u_{t}^2$\")\n  )\n\n(p1 | p2) +\n  plot_annotation(\n    title = \"Verificando homocedasticidade\",\n    subtitle = \"Picos na série do quadrado dos resíduos indicam a presença de heterocedasticidade.\"\n  ) &\n  theme_ts\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-29-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n### Arch test\n\nO test ARCH (autoregressive conditional heteroskedasticity) é, conceitualmente, muito similar ao teste Breusch-Godfrey, visto anteriormente. A ideia é fazer uma regressão do quadrado do resíduo contra seus valores defasados para verificar a presença de heteroscedasticidade condicional. A hipótese nula do teste é de que não há efeitos ARCH presentes.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nFinTS::ArchTest(u1, lags = 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tARCH LM-test; Null hypothesis: no ARCH effects\n\ndata:  u1\nChi-squared = 11.216, df = 4, p-value = 0.02424\n```\n\n\n:::\n:::\n\n\n## Normalidade dos resíduos\n\nO teste Jarque-Bera avalia se os resíduos seguem uma distribuição normal. A normalidade dos resíduos é importante para a validade dos intervalos de confiança das previsões.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntseries::jarque.bera.test(u1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tJarque Bera Test\n\ndata:  u1\nX-squared = 4.8301, df = 2, p-value = 0.08936\n```\n\n\n:::\n:::\n\n\nA função `checkresiduals` oferece uma visualização completa dos diagnósticos do modelo, combinando o gráfico da série dos resíduos, a FAC e um histograma com o resultado do teste Ljung-Box.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncheckresiduals(m1) + theme_ts\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-32-1.png){fig-align='center' width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tLjung-Box test\n\ndata:  Residuals from ARIMA(0,1,0) with drift\nQ* = 16.311, df = 8, p-value = 0.03814\n\nModel df: 0.   Total lags used: 8\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n# 5. Comparação de Modelos\n\nApós estimar os quatro modelos e verificar seus diagnósticos, o próximo passo é compará-los para selecionar o mais apropriado. A tabela abaixo mostra os critérios de informação para cada modelo estimado.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Extrai informações dos modelos\ntab_models = data.frame(\n  Modelo = c(\n    \"ARIMA(0,1,0)\",\n    \"ARIMA(1,1,1)\",\n    \"ARIMA(1,1,0)\",\n    \"ARIMA(0,1,1)\",\n    \"ARIMA(1,1,1) com drift\"\n  ),\n  AIC = c(m1$aic, m2$aic, m3$aic, m4$aic, m5$aic),\n  AICc = c(m1$aicc, m2$aicc, m3$aicc, m4$aicc, m5$aicc),\n  BIC = c(m1$bic, m2$bic, m3$bic, m4$bic, m5$bic),\n  sigma2 = c(m1$sigma2, m2$sigma2, m3$sigma2, m4$sigma2, m5$sigma2)\n)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-bordered table-hover table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> Modelo </th>\n   <th style=\"text-align:center;\"> AIC </th>\n   <th style=\"text-align:center;\"> AICc </th>\n   <th style=\"text-align:center;\"> BIC </th>\n   <th style=\"text-align:center;\"> sigma2 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> ARIMA(0,1,0) </td>\n   <td style=\"text-align:center;\"> 318.6831 </td>\n   <td style=\"text-align:center;\"> 318.8410 </td>\n   <td style=\"text-align:center;\"> 323.4220 </td>\n   <td style=\"text-align:center;\"> 3.18430 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> ARIMA(1,1,1) </td>\n   <td style=\"text-align:center;\"> 313.1667 </td>\n   <td style=\"text-align:center;\"> 313.4867 </td>\n   <td style=\"text-align:center;\"> 320.2750 </td>\n   <td style=\"text-align:center;\"> 2.90749 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> ARIMA(1,1,0) </td>\n   <td style=\"text-align:center;\"> 320.2546 </td>\n   <td style=\"text-align:center;\"> 320.4125 </td>\n   <td style=\"text-align:center;\"> 324.9935 </td>\n   <td style=\"text-align:center;\"> 3.23828 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> ARIMA(0,1,1) </td>\n   <td style=\"text-align:center;\"> 325.5904 </td>\n   <td style=\"text-align:center;\"> 325.7483 </td>\n   <td style=\"text-align:center;\"> 330.3293 </td>\n   <td style=\"text-align:center;\"> 3.46862 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> ARIMA(1,1,1) com drift </td>\n   <td style=\"text-align:center;\"> 313.3759 </td>\n   <td style=\"text-align:center;\"> 313.9165 </td>\n   <td style=\"text-align:center;\"> 322.8537 </td>\n   <td style=\"text-align:center;\"> 2.89641 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nOs critérios de informação penalizam modelos mais complexos, buscando encontrar o melhor equilíbrio entre ajuste aos dados e parcimônia. Menores valores indicam melhores modelos. Tanto o AIC quanto o BIC indicam que o modelo ARIMA(1,1,1) apresenta o melhor ajuste.\n\nVale notar que o modelo ARIMA(0,1,0), também conhecido como random walk, apresenta os piores critérios. Este modelo assume que a melhor previsão para o próximo período é simplesmente o valor atual, sem considerar a estrutura de dependência temporal da série.\n\n## Modelo final\n\nCom base nos diagnósticos e critérios de informação, selecionamos o modelo ARIMA(1,1,1) como o mais apropriado para a série de consumo. O modelo final estimado é:\n\n$$\n\\Delta y_{t} = 0.9449 \\Delta y_{t-1} - 0.7277 \\varepsilon_{t-1}\n$$\n\nEste modelo indica que a primeira diferença do consumo possui alta persistência (coeficiente AR próximo de 1) e também incorpora choques passados através do componente MA.\n\n# 6. Previsão\n\nCom o modelo final estimado, podemos gerar previsões para períodos futuros. O código abaixo gera previsões para os próximos 8 trimestres (2 anos) usando o modelo ARIMA(1,1,1).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Gera previsões\nh = length(test)\nfcst = forecast(m2, h = h)\n```\n:::\n\n\nO gráfico abaixo mostra a série histórica junto com as previsões e seus respectivos intervalos de confiança de 80% e 95%.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-36-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nOs intervalos de confiança aumentam à medida que avançamos no horizonte de previsão, refletindo a crescente incerteza sobre valores futuros. Esta é uma característica comum de modelos de séries temporais.\n\n## Avaliando a precisão\n\nPara avaliar a qualidade das previsões, podemos compará-las com os valores observados no conjunto de teste que separamos anteriormente.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcula métricas de erro\naccuracy(fcst, test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                    ME     RMSE      MAE        MPE      MAPE      MASE\nTraining set 0.0923341 1.672860 1.253162 0.08911013 0.9504304 0.2512341\nTest set     6.0885365 8.376132 6.584560 3.43589199 3.7244126 1.3200731\n                  ACF1 Theil's U\nTraining set 0.0485215        NA\nTest set     0.8172789  8.097087\n```\n\n\n:::\n:::\n\n\nA função `accuracy` calcula diversas métricas de erro de previsão. O RMSE (Root Mean Squared Error) e o MAE (Mean Absolute Error) medem o tamanho típico dos erros de previsão. O MAPE (Mean Absolute Percentage Error) expressa o erro em termos percentuais.\n\nNote que as métricas calculadas sobre o conjunto de treino (Training set) são naturalmente melhores do que as calculadas sobre o conjunto de teste (Test set), pois o modelo foi estimado usando os dados de treino.\n\nPodemos fazer os mesmos cálculos para todos os modelos usando `lapply` e definindo uma função que extrai as métricas de erro somente para o conjunto de teste.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodels = list(\n  \"ARIMA(0,1,0)\" = m1,\n  \"ARIMA (1,1,1)\" = m2,\n  \"ARIMA (1,1,0)\" = m3,\n  \"ARIMA (0,1,1)\" = m4,\n  \"ARIMA (1,1,1) com drift\" = m5\n)\n\ncollect_measures = function(m) {\n  fcast = forecast(m, h = length(test))\n  measures = accuracy(fcast, test)\n  measures = measures[2, c(\"ME\", \"RMSE\", \"MAE\", \"MAPE\")]\n  return(measures)\n}\n\nmeasures = lapply(models, collect_measures)\ntab_measures = do.call(rbind, measures)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-bordered table-hover table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:center;\"> ME </th>\n   <th style=\"text-align:center;\"> RMSE </th>\n   <th style=\"text-align:center;\"> MAE </th>\n   <th style=\"text-align:center;\"> MAPE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> ARIMA(0,1,0) </td>\n   <td style=\"text-align:center;\"> -7.38142 </td>\n   <td style=\"text-align:center;\"> 7.54294 </td>\n   <td style=\"text-align:center;\"> 7.38142 </td>\n   <td style=\"text-align:center;\"> 4.22250 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ARIMA (1,1,1) </td>\n   <td style=\"text-align:center;\"> 6.08854 </td>\n   <td style=\"text-align:center;\"> 8.37613 </td>\n   <td style=\"text-align:center;\"> 6.58456 </td>\n   <td style=\"text-align:center;\"> 3.72441 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ARIMA (1,1,0) </td>\n   <td style=\"text-align:center;\"> 0.35612 </td>\n   <td style=\"text-align:center;\"> 2.86907 </td>\n   <td style=\"text-align:center;\"> 2.63088 </td>\n   <td style=\"text-align:center;\"> 1.50421 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ARIMA (0,1,1) </td>\n   <td style=\"text-align:center;\"> -0.50112 </td>\n   <td style=\"text-align:center;\"> 2.83434 </td>\n   <td style=\"text-align:center;\"> 2.49317 </td>\n   <td style=\"text-align:center;\"> 1.43254 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ARIMA (1,1,1) com drift </td>\n   <td style=\"text-align:center;\"> -0.72171 </td>\n   <td style=\"text-align:center;\"> 1.71544 </td>\n   <td style=\"text-align:center;\"> 1.38625 </td>\n   <td style=\"text-align:center;\"> 0.80201 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nNote como, apesar do ARIMA (1,1,1) ter os melhores critérios de informação, os modelos ARIMA (0,1,1) e ARIMA (1,1,0) apresentaram melhores métricas de erro. O modelo ARIMA (1,1,1), sobretudo, as melhores métricas de erro.\n\nVisualmente, podemos ver estes modelos tem uma melhor performance pois eles não seguem a trajetória de queda recente da série. Na verdade, ambos os modelos ARIMA (0,1,1) e ARIMA (1,1,0) geram uma previsão \"naive\" onde o último valor da série é repetido diversas vezes.\n\nVale notar, que nosso período de train termina no último trimestre de 2015, em meio à crise econômica. Nosso modelo ARIMA (1,1,1) tem ótima performance durante os primeiros 4 trimestres de 2016: ele continua prevendo a queda no consumo acuradamente. Contudo, dada a sua estrutura matemática, ele continua a gerar previsões de que o consumo vai continuar diminuindo. Já no modelo ARIMA (1,1,1) com drift as previsões voltam a aumentar em valor à medida que o tempo passa.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nf1 = forecast(m2, h = length(test))\nf2 = forecast(m3, h = length(test))\nf3 = forecast(m5, h = length(test))\n\nautoplot(train) +\n  autolayer(test, series = \"Obsevado\") +\n  autolayer(f1$mean, series = \"ARIMA (1,1,1)\") +\n  autolayer(f2$mean, series = \"ARIMA (1,1,0)\") +\n  autolayer(f3$mean, series = \"ARIMA (1,1,1) com drift\") +\n  labs(\n    title = \"Previsão do Consumo das Famílias\",\n    subtitle = \"Modelo ARIMA(1,1,1) com intervalos de confiança de 80% e 95%\",\n    x = NULL,\n    y = \"Index (100 = 1995)\"\n  ) +\n  scale_color_manual(\n    name = \"\",\n    values = c(\"#2C6BB3\", \"#1abc9c\", \"#f39c12\", \"#34495e\")\n  ) +\n  theme_ts\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-40-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nO gráfico abaixo faz uma previsão 12 anos à frente para enfatizar o comportamento de longo prazo destes modelos. Os modelos ARIMA (1, 1, 0) rapidamente converge para um valor constante. As previsões de longo prazo do ARIMA (1,1,1) com drift seguem uma tendência linear simples, enquanto o modelo sem drift converge lentamente para uma constante.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nf1 = forecast(m2, h = 48)\nf2 = forecast(m3, h = 48)\nf3 = forecast(m5, h = 48)\n\n\nautoplot(train) +\n  autolayer(f1$mean, series = \"ARIMA (1,1,1)\") +\n  autolayer(f2$mean, series = \"ARIMA (1,1,0)\") +\n  autolayer(f3$mean, series = \"ARIMA (1,1,1) com drift\") +\n  labs(\n    title = \"Previsão do Consumo das Famílias\",\n    subtitle = \"Modelo ARIMA(1,1,1) com intervalos de confiança de 80% e 95%\",\n    x = NULL,\n    y = \"Index (100 = 1995)\"\n  ) +\n  scale_color_manual(\n    name = \"\",\n    values = c(\"#2C6BB3\", \"#1abc9c\", \"#f39c12\", \"#34495e\")\n  ) +\n  theme_ts\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-41-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nEsta discussão mostra a complexidade da previsão de séries de tempo e como seguir roteiros automatizados podem levar a erros. No nosso exemplo, a escolha do corte train/test levou a série ao meio de uma crise econômica, o que tem impactos grandes sobre a estimação dos modelos. Há maneiras de contornar isto usando, por exemplo, cross-validation para selecionar janelas de train/test variáveis, ou incorporando outros dados para ajudar a melhor lidar com o período de recessão.\n\nTambém fica evidente como os modelos ARIMA geram previsões de longo prazo questionáveis. Dada a estrutura matemática destes modelos, eles geram previsões que podem ser bastante irrealistas em horizontes grandes de tempo. Assim, tipicamente, deve-se usar modelos ARIMA como uma ferramenta de previsão de curto prazo.\n\n# 7. Resumo\n\nNeste post, demonstramos a aplicação completa da metodologia Box-Jenkins para estimar modelos ARIMA em séries temporais macroeconômicas brasileiras. Seguindo as etapas de identificação, estimação, verificação e previsão, modelamos a série de consumo das famílias brasileiras.\n\n## Principais Conclusões\n\n1. **Estacionaridade**: A série de consumo apresentou raiz unitária, exigindo uma diferenciação (d=1) para torná-la estacionária.\n\n2. **Identificação**: A análise das funções de autocorrelação (FAC e FACP) sugeriu um modelo ARIMA(1,1,1) como candidato de ordem máxima.\n\n3. **Diagnóstico**: A verificação dos resíduos através de testes estatísticos e análise gráfica confirmou que o modelo ARIMA(1,1,1) apresenta resíduos bem comportados, sem autocorrelação significativa.\n\n4. **Comparação**: Os critérios AIC e BIC confirmaram que o modelo ARIMA(1,1,1) oferece o melhor equilíbrio entre ajuste e parcimônia.\n\n5. **Previsão**: O modelo final foi usado para gerar previsões fora da amostra, com intervalos de confiança apropriados que refletem a incerteza crescente ao longo do horizonte de previsão. A previsão do modelo escolhido foi inicialmente boa, mas se deteriorou ao longo do intervalo. Modelos alternativos tiveram melhor performance preditiva.\n\n## Quando usar modelos ARIMA\n\nModelos ARIMA são apropriados quando:\n\n- Trabalha-se com séries temporais univariadas.\n- Há evidência de dependência temporal nos dados.\n- O objetivo é fazer previsões de curto a médio prazo.\n- Busca-se um modelo parcimonioso e fácil de estimar.\n\n**Limitações importantes:**\n\n- Não incorpora informação de outras variáveis (para isso, considere modelos ARIMAX ou VAR).\n- A capacidade preditiva tende a deteriorar rapidamente em horizontes longos.\n- Quebras estruturais podem invalidar o modelo.\n\n## Alternativas e extensões\n\n- **auto.arima()**: O pacote `forecast` oferece a função `auto.arima()` que seleciona automaticamente a ordem do modelo usando critérios de informação\n- **Modelos sazonais**: Para séries com sazonalidade, considere modelos SARIMA\n- **Modelos multivariados**: Para incorporar múltiplas séries, considere modelos VAR ou VECM\n- **Não-linearidade**: Para capturar assimetrias e não-linearidades, considere modelos GARCH ou TAR\n\n## Posts Relacionados\n\n- [Modelos ARMA: exemplo simples](https://restateinsight.com/posts/general-posts/repost-arma-exemplo-simples/)\n- [Médias móveis em R](https://restateinsight.com/posts/general-posts/2024-02-media-movel/)\n- [Sazonalidade em séries de tempo](https://restateinsight.com/posts/general-posts/2024-01-sazonalidade/)\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}