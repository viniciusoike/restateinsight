{
  "hash": "bb2ca3c647d03977afb70b30c5ff324c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Gradient Descent\"\ndate: \"2024-02-05\"\ncategories: ['data-science', 'tutorial-R', 'econometria']\ndescription: \"O algoritmo de Gradient Descent é um otimizador amplamente utilizado em Machine Learning para minimizar funções de custo. Este otimizador simples é baseado na direção do gradiente da função. Neste post explico a matemática que sustenta este método e mostro como implementá-lo passo a passo.\"\nexecute:\n  warning: false\n  message: false\n---\n\n\n\n# Entendendo o Gradiente Descent (GD)\n\nO Gradient Descent (GD), também conhecido como **steepest descent** ou até como Stochastic Gradient Descent (SGD)[^1], é um algoritmo fundamental em otimização que desempenha um papel crucial no ajuste de parâmetros de modelos de machine learning. Basicamente, o GD utiliza a informação do gradiente de uma função, que se quer otimizar, para encontrar o \"caminho\" em que ela decaí mais rapidamente.\n\n[^1]: Apesar dos métodos serem formalmente diferentes, a sua essência é idêntica a ponto de ser comum confundi-los. O SGD é uma \"aproximação\" do GD, onde apenas uma parte (amostra) dos dados é utilizada para calcular o gradiente. Neste sentido, o SGD é muito mais eficiente do ponto de vista computacional.\n\nNo caso mais típico, da minimização de uma função de perda, o GD ou SGD usa o gradiente da função para encontrar os valores dos parâmetros que minimizam esta função. O algoritmo opera iterativamente e, idealmente, aproxima-se gradualmente da solução correta.\n\nAssim, a utilidade geral do GD reside na sua capacidade de iterativamente encontrar o mínimo de funções usando relativamente pouca informação.\n\n## Regressão Simples\n\n### Um pouco de matemática\n\nPara tornar as coisas mais concretas vamos considerar o caso de uma regressão linear simples. Temos uma variável de resposta $y$ que será \"explicada\" por uma variável independente (feature) $x$ . A relação é modelada de maneira linear como:\n\n$$\ny = \\beta_{0} + \\beta_{1}x + \\varepsilon\n$$\n\nA equação acima descreve o nosso modelo, que será estimado posteriormente. Com este modelo podemos calcular os valores preditos $\\hat{y_{i}}$ que serão comparados com os valores observados (reais) $y_{i}$. Nosso objetivo é ajustar os parâmetros $\\beta_{0}$ e $\\beta_{1}$ para minimizar a função de custo, que pode ser representada como o Erro Quadrático Médio (MSE, do inglês *Mean Squared Error*):\n\n$$\n\\text{MSE} =  \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_{i}})^2= \\frac{1}{n} \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_1 X_i))^2\n$$\n\nPara atualizar os parâmetros $\\beta_0$ e $\\beta_1$ usando GD, precisamos calcular o gradiente da função de custo em relação a esses parâmetros. A primeira derivada da função de custo em relação a $\\beta_0$ e $\\beta_1$ nos dá as direções em que devemos ajustar esses parâmetros para minimizar a função de custo.\n\nA primeira derivada da função de custo em relação a $\\beta_0$ é dada por:\n\n$$\n\\frac{\\partial \\text{MSE}}{\\partial \\beta_0} = \\frac{-2}{n} \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_1 x_i))\n$$\n\nE a primeira derivada da função de custo em relação a $\\beta_1$ é dada por:\n\n$$\n\\frac{\\partial \\text{MSE}}{\\partial \\beta_1} = \\frac{-2}{n} \\sum_{i=1}^{n} x_i (y_i - (\\beta_0 + \\beta_1 x_i))\n$$\n\nEssas derivadas nos fornecem a direção em que devemos ajustar os parâmetros para minimizar a função de custo.\n\n### Implementando o algoritmo\n\nO algortimo de GD funciona iterativamente O algoritmo de SGD atualiza o parâmetro $\\beta^{t}$ a cada iteração t, onde $\\beta^{0}$ é dado, usando o gradiente $\\nabla_{\\beta}^t$ da seguinte maneira:\n\n$$\n\\beta^{t+1} = \\beta^{t} - \\gamma\\nabla_{\\beta}^{t}\n$$\n\nonde $\\gamma$ é um número real não-negativo, tipicamente próximo de 0.001, chamado \"learning rate\". Quanto maior for o valor de $\\gamma$ maiores serão os \"passos\" no processo de atualização; inversamente, quanto menor for o valor de $\\gamma$ menores serão os \"passos\"no processo iterativo.\n\nPara implementar o passo-a-passo do algoritmo vamos usar a base `mtcars`. O primeiro passo é ajustar os dados usando a função `scale`. Em seguida, separamos alguns objetos úteis para facilitar a exposição.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#> Regularizar os dados\nmtcars_scaled <- as.data.frame(scale(mtcars))\n\ny <- mtcars_scaled$mpg\nx <- mtcars_scaled$wt\nN <- nrow(mtcars_scaled)\n```\n:::\n\n\nVamos fazer a regressão de `mpg` (milhas por galão), uma medida da eficiência do veículo, contra `wt` (peso), o peso do veículo. Visualmente, parece haver uma relação linear decrescente entre as variáveis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(y ~ x)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nAntes de fazer o loop, vamos decompor o algoritmo em etapas. Primeiro, precisa-se de valores iniciais para os parâmetros $\\beta_{0}$ e $\\beta_{1}$. Por simplicidade, vamos sortear números aleatórios entre 0 e 1 a partir de uma distribuição uniforme. Com estes valores será possível calcular o valor de $\\hat{y}_{i}^0$, onde 0 indica que estamos na iteração de valor 0.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb0 <- runif(1)\nb1 <- runif(1)\n\n(yhat <- b0 + b1 * x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] -0.17140720  0.05168499 -0.43386860  0.34914125  0.54598730  0.56348473\n [7]  0.65972058  0.32726947  0.29227461  0.54598730  0.54598730  1.09715625\n[13]  0.79969999  0.84344356  2.12950443  2.28173204  2.21261721 -0.53885316\n[19] -1.05065289 -0.85818120 -0.30701225  0.61597701  0.54161295  0.89593584\n[25]  0.90031019 -0.77069407 -0.59134544 -1.13988977  0.30977204 -0.04017650\n[31]  0.65972058 -0.03142778\n```\n\n\n:::\n:::\n\n\nNão é necessário, mas é instrutivo calcular a função de perda.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(mse <- mean((y - yhat)^2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.240961\n```\n\n\n:::\n:::\n\n\nAgora, calculamos o valor do gradiente neste ponto.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(gb0 <- sum(y - yhat) * (-2 / N))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.7022194\n```\n\n\n:::\n\n```{.r .cell-code}\n(gb1 <- sum((y - yhat) * x) * (-2 / N))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.339637\n```\n\n\n:::\n:::\n\n\nPor fim, o valor dos parâmetros é atualizado segundo a fórmula matemática do algoritmo. Utiliza-se $g = 0.01$ como valor para a learning-rate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng = 0.01\n\n(b0_new <- b0 - g * gb0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3440875\n```\n\n\n:::\n\n```{.r .cell-code}\n(b1_new <- b1 - g * gb1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.822628\n```\n\n\n:::\n:::\n\n\nEste processo será repetido $T$ vezes até que se atinja algum critério de convergência. Em geral, estabelece-se\n\n1.  **Um número máximo de iterações**. (10.000 iterações, por exemplo).\n2.  **Um valor mínimo de mudança na estimativa dos parâmetros**. Isto é, quando o valor das estimativas para de mudar significativamente, entende-se que ele convergiu para um valor satisfatório.\n\nPara deixar o loop abaixo mais simples, vou simplesmente estabelecer um número máximo de 5000 iterações. O código segue abaixo. Note que algumas partes do código acima foram repetidas por conveniência da leitura.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_iterations <- 1000\n#> Learning-rate\ng <- 0.01\n\ny <- mtcars_scaled$mpg\nx <- mtcars_scaled$wt\nN <- nrow(mtcars_scaled)\n\n#> Valores iniciais para estimativas dos parâmetros\nb0 <- runif(1)\nb1 <- runif(1)\n\nfor (i in seq_len(num_iterations)) {\n  if (i %% 100 == 0) {\n    cat(\"Iteração: \", i, \"\\n\")\n  }\n\n  #> Calcula o valor previsto\n  yhat <- b0 + b1 * x\n\n  #> Calcula a \"função de perda\"\n  error <- y - yhat\n  mse <- mean(error^2)\n\n  if (i %% 100 == 0) {\n    cat(\"Valor da perda: \", as.numeric(mse), \"\\n\")\n  }\n\n  #> Calcula o gradiente nos pontos atuais\n  gb0 <- sum(y - yhat) * (-2 / N)\n  gb1 <- sum((y - yhat) * x) * (-2 / N)\n  #> Atualiza o valor dos parâmetros usando o gradiente\n  b0_new <- b0 - g * gb0\n  b1_new <- b1 - g * gb1\n\n  b0 <- b0_new\n  b1 <- b1_new\n\n  if (i %% 100 == 0) {\n    cat(\"Betas: \", c(b0, b1), \"\\n\\n\")\n  }\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIteração:  100 \nValor da perda:  0.3013997 \nBetas:  0.1179619 -0.6505911 \n\nIteração:  200 \nValor da perda:  0.2406465 \nBetas:  0.01564405 -0.8369768 \n\nIteração:  300 \nValor da perda:  0.2394667 \nBetas:  0.002074708 -0.8633224 \n\nIteração:  400 \nValor da perda:  0.2394437 \nBetas:  0.0002751468 -0.8670463 \n\nIteração:  500 \nValor da perda:  0.2394432 \nBetas:  3.648985e-05 -0.8675727 \n\nIteração:  600 \nValor da perda:  0.2394432 \nBetas:  4.839267e-06 -0.8676471 \n\nIteração:  700 \nValor da perda:  0.2394432 \nBetas:  6.417815e-07 -0.8676576 \n\nIteração:  800 \nValor da perda:  0.2394432 \nBetas:  8.511277e-08 -0.8676591 \n\nIteração:  900 \nValor da perda:  0.2394432 \nBetas:  1.128762e-08 -0.8676593 \n\nIteração:  1000 \nValor da perda:  0.2394432 \nBetas:  1.49696e-09 -0.8676594 \n```\n\n\n:::\n:::\n\n\nPara recuperar o valor final dos betas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc(b0, b1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1.496960e-09 -8.676594e-01\n```\n\n\n:::\n:::\n\n\nPara efeito didático, vamos comparar estas estimativas finais contra os valores estimados pela função `lm`. Note que os valores estão muito similares\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model_lm <- lm(mpg ~ wt, data = mtcars_scaled))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars_scaled)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.75381 -0.39236 -0.02077  0.23388  1.14033 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.040e-15  8.934e-02   0.000        1    \nwt          -8.677e-01  9.077e-02  -9.559 1.29e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5054 on 30 degrees of freedom\nMultiple R-squared:  0.7528,\tAdjusted R-squared:  0.7446 \nF-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n```\n\n\n:::\n:::\n\n\n### Visualizando o processo\n\nSempre que possível, é útil visualizar o funcionamento do algoritmo em gráficos. Como estamos trabalhando com um exemplo simples, pode-se plotar os resultados gradativamente num gráfico de dispersão. O código abaixo mostra como a linha de ajuste (linha de regressão) vai se alterando à medida que se aumenta o número de amostras.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nnum_iterations <- 1000\n#> Learning-rate\nalpha <- 0.01\n\ny <- dat$mpg\nx <- dat$wt\nN <- nrow(dat)\n\n#> Valores iniciais para estimativas dos parâmetros\nb0 <- runif(1)\nb1 <- runif(1)\n\nbetas <- matrix(ncol = 2, nrow = num_iterations)\nfor (i in seq_len(num_iterations)) {\n  #> Calcula o valor previsto\n  yhat <- b0 + b1 * x\n\n  #> Calcula a \"função de perda\"\n  error <- y - yhat\n  mse <- mean(error^2)\n\n  #> Calcula o gradiente nos pontos atuais\n  gb0 <- sum(y - yhat) * (-2 / N)\n  gb1 <- sum((y - yhat) * dat$wt) * (-2 / N)\n  #> Atualiza o valor dos parâmetros usando o gradiente\n  b0_new <- b0 - alpha * gb0\n  b1_new <- b1 - alpha * gb1\n\n  b0 <- b0_new\n  b1 <- b1_new\n\n  betas[i, 1] <- b0_new\n  betas[i, 2] <- b1_new\n}\n\nsel <- c(1:10, seq(20, 100, 10), seq(100, 1000, 50))\n\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(tibble)\n\ntbl_betas <- tibble(\n  iter = sel,\n  beta0 = betas[sel, 1],\n  beta1 = betas[sel, 2]\n)\n\nggplot() +\n  geom_point(\n    data = dat,\n    aes(x = wt, y = mpg),\n    shape = 21\n  ) +\n  geom_abline(\n    data = tbl_betas,\n    aes(intercept = beta0, slope = beta1),\n    color = \"#CB181D\",\n    lwd = 0.8\n  ) +\n  geom_text(\n    data = tbl_betas,\n    aes(x = 1.8, y = 1.8, label = paste(\"Iteration:\", iter)),\n    size = 5\n  ) +\n  transition_states(iter) +\n  enter_fade() +\n  exit_shrink() +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.gif)\n:::\n:::\n\n\n## Regressão Múltipla\n\nAgora vamos considerar o caso de regressão múltipla, onde temos várias variáveis independentes. A equação do modelo é generalizada para:\n\n$$\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_k x_k\n$$\n\nIsto é, agora temos $k$ variáveis independentes, $x_1, x_2, ..., x_k$, e temos $k$ coeficientes, $\\beta_0, \\beta_1, \\beta_2, ..., \\beta_k$, a ser estimados. A função de custo torna-se:\n\n$$\n\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_{1} x_{i1} + \\beta_2 x_{i2} + ... + \\beta_k X_{ik}))^2\n$$\n\nAgora, as derivadas parciais da função de custo em relação a cada parâmetro $\\beta$ são calculadas e utilizadas para atualizar os coeficientes durante o GD.\n\n$$\n\\nabla_{\\beta} = (\\frac{\\partial\\text{MSE}}{\\partial\\beta_{0}}, \\frac{\\partial\\text{MSE}}{\\partial\\beta_{1}}, ..., \\frac{\\partial\\text{MSE}}{\\partial\\beta_{k}})\n$$\n\n### Regressão Múltipla com Matrizes\n\nNa regressão múltipla, podemos representar os dados de entrada $X$ e os parâmetros do modelo $\\beta$ como matrizes. Esta forma de representação é mais prática quando temos muitas variáveis e permite dispensar o uso de somatórios.\n\nSuponha que tenhamos $n$ observações e $k$ variáveis independentes.\n\nAs observações de entrada podem ser organizadas em uma matriz $X$ de dimensão $n \\times (k+1)$, onde a primeira coluna é composta por $1$s para representar o intercepto do modelo. Assim, a matriz $X$ é dada por:\n\n$$\nX = \\begin{bmatrix}\n1 & x_{11} & x_{12} & \\cdots & x_{1p} \\\\\n1 & x_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_{n1} & x_{n2} & \\cdots & x_{nk}\n\\end{bmatrix}\n$$\n\nOs parâmetros do modelo $\\beta$ podem ser representados como um vetor de coeficientes de dimensão $(k+1) \\times 1$. Assim, o vetor $\\beta$ é dado por:\n\n$$\n\\beta = \\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\vdots \\\\\n\\beta_k\n\\end{bmatrix}\n$$\n\nA resposta $y$ pode ser representada como um vetor de dimensão $n \\times 1$.\n\n$$\ny = \\begin{bmatrix}\ny_0 \\\\\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix}\n$$\n\nNote que o problema de minimização acima é equivalente a minimizar a soma do erro ao quadrado do modelo. Isto acontece pois o erro, no caso mais simples, é simplesmente\n\n$$\n\\varepsilon = y_i - \\hat{y_i} = y_i - \\beta_{0} - \\beta_{1}x_i\n$$\n\ne o problema de minimizar:\n\n$$\n\\text{min } \\varepsilon^2 = (y_i - \\hat{y_i})^2\n$$\n\nEm termos matriciais temos:\n\n$$\ne = y - \\hat{y} = y - X\\beta\n$$ e agora o problema de minimizar\n\n$$\n\\text{min } e^te = (y - X\\beta)^t(y-XB)\n$$\n\nPara encontrar o gradiente da função de custo $e^te$, em relação aos parâmetros $\\beta$, podemos usar cálculo matricial.\n\nO gradiente $\\nabla_{\\beta} (e'e)$ é dado por:\n\n$$\n\\nabla_{\\beta} (e'e) = -2X^T(y - X\\beta)\n$$\n\nOnde $X^T$ representa a transposta da matriz X. Este gradiente nos fornece a direção em que devemos ajustar os (múltiplos) parâmetros $\\beta$ para minimizar a função de custo $e'e$.\n\n## Implementando o algoritmo\n\nDesta vez, vamos implementar tanto o gradiente como a função de perda como `function`s no `R`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrad <- function(beta) {\n\n  (2/N) * t(X) %*% (X %*% beta - y)\n\n}\n\nloss <- function(beta) {\n\n  e = y - X %*% beta\n\n  t(e) %*% e\n\n}\n```\n:::\n\n\n### O modelo\n\nNosso modelo de regressão agora terá a forma:\n\n$$\n\\text{mpg} = \\beta_{0} + \\beta_{1}\\text{wt} + \\beta_{2}\\text{qsec}+ \\beta_{3}\\text{am}\n$$\n\nonde `mpg` e `wt` tem as mesmas definições dadas acima; já `qsec` é uma medida de velocidade do veículo e `am` é uma variável binária que indica se o câmbio do veículo é manual ou automático.\n\n### Os dados\n\nDesta vez, o preparo dos dados será feito usando o pacote `dplyr`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\ndat <- mtcars |>\n  select(c(\"mpg\", \"wt\", \"qsec\", \"am\")) |>\n  mutate(across(everything(), ~as.numeric(scale(.x))))\n\ny <- dat$mpg\nX <- as.matrix(dat[, c(\"wt\", \"qsec\", \"am\")])\nX <- cbind(1, X)\ncolnames(X)[1] <- c(\"coef\")\nN <- nrow(X)\n```\n:::\n\n\n### Primeira iteração\n\nNovamente, para ganhar um pouco de intuição vamos rodar o\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#> Valor inicial para os betas\nbeta <- runif(ncol(X))\n\n# Opcional\n#> Computa a \"predição\" do modelo\nyhat <- X %*% beta\n#> Calcula o valor da função de perda\nl <- loss(beta)\n\n#> Atualiza o valor dos beta\nbeta_new <- beta - alpha * grad(beta)\n```\n:::\n\n\n### O loop completo\n\nO código abaixo mostra o loop completo. Fora algumas pequenas modificações, ele é exatamente igual ao loop anterior. Neste segundo exemplo, eu reduzo o valor da learning-rate e aumento o número de iterações.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nbeta <- runif(ncol(X))\nnum_iterations <- 10000\nalpha <- 0.001\n\nfor (i in seq_len(num_iterations)) {\n\n  if (i %% 1000 == 0) cat(\"Iteração: \", i, \"\\n\")\n\n  #> Calcula o valor previsto\n  yhat <- X %*% beta\n\n  #> Calcula a \"função de perda\"\n  vl_loss <- loss(beta)\n\n  if (i %% 1000 == 0) {\n    cat(\"Valor da perda: \", as.numeric(vl_loss), \"\\n\")\n  }\n\n  #> Calcula o gradiente nos pontos atuais\n  grad_current <- grad(beta)\n  #> Atualiza o valor dos parâmetros usando o gradiente\n  beta_current <- beta - alpha * grad_current\n\n  beta <- beta_current\n\n  if (i %% 1000 == 0) {\n    cat(\"Betas: \", beta, \"\\n\\n\")\n  }\n\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIteração:  1000 \nValor da perda:  7.843567 \nBetas:  0.1035636 -0.1690523 0.5729491 0.6570115 \n\nIteração:  2000 \nValor da perda:  5.904957 \nBetas:  0.01398776 -0.3430823 0.5113749 0.53897 \n\nIteração:  3000 \nValor da perda:  5.220956 \nBetas:  0.001889251 -0.4398704 0.4639382 0.4426585 \n\nIteração:  4000 \nValor da perda:  4.914118 \nBetas:  0.0002551707 -0.5040486 0.4311833 0.377357 \n\nIteração:  5000 \nValor da perda:  4.775269 \nBetas:  3.446451e-05 -0.5471717 0.4090413 0.3334177 \n\nIteração:  6000 \nValor da perda:  4.712415 \nBetas:  4.654933e-06 -0.5761808 0.3941314 0.3038562 \n\nIteração:  7000 \nValor da perda:  4.683963 \nBetas:  6.287163e-07 -0.5956981 0.3840982 0.2839671 \n\nIteração:  8000 \nValor da perda:  4.671083 \nBetas:  8.491727e-08 -0.6088296 0.3773476 0.2705854 \n\nIteração:  9000 \nValor da perda:  4.665252 \nBetas:  1.146931e-08 -0.6176647 0.3728056 0.2615821 \n\nIteração:  10000 \nValor da perda:  4.662613 \nBetas:  1.549098e-09 -0.6236091 0.3697497 0.2555244 \n```\n\n\n:::\n:::\n\n\nPor fim, temos o valor final dos betas estimados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_current\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              [,1]\ncoef  1.549098e-09\nwt   -6.236091e-01\nqsec  3.697497e-01\nam    2.555244e-01\n```\n\n\n:::\n:::\n\n\nNovamente, podemos comparar estas estimativas com aquelas calculadas pela função `lm`. Note que, neste caso, mesmo após 10.000 iterações ainda há algumas pequenas divergências entre os valores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model_lm <- lm(mpg ~ wt + qsec + am, data = dat))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ wt + qsec + am, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5776 -0.2581 -0.1204  0.2341  0.7734 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.485e-15  7.212e-02   0.000 1.000000    \nwt          -6.358e-01  1.155e-01  -5.507 6.95e-06 ***\nqsec         3.635e-01  8.559e-02   4.247 0.000216 ***\nam           2.431e-01  1.168e-01   2.081 0.046716 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.408 on 28 degrees of freedom\nMultiple R-squared:  0.8497,\tAdjusted R-squared:  0.8336 \nF-statistic: 52.75 on 3 and 28 DF,  p-value: 1.21e-11\n```\n\n\n:::\n:::\n\n\n## Conclusão\n\nO Gradiente Descendente é uma ferramenta poderosa para otimização em aprendizado de máquina e outros campos. Neste post, explicamos a matemática por trás do GD, mostramos como derivar o gradiente tanto para regressão linear simples quanto múltipla, e como entender o funcionamento deste algoritmo fundamental.\n\n# Posts relacionados\n\n-   [Estimação de Máxima Verossimilhança no R](https://restateinsight.com/posts/general-posts/repost-emv-no-r/)\n\n-   [OLS com matrizes no R](https://restateinsight.com/posts/general-posts/repost-ols-com-matrizes/)\n\n-   [Otimização numérica: métodos de Newton](https://restateinsight.com/posts/general-posts/repost-otimizacao-newton/)\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}