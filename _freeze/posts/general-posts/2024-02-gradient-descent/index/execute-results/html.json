{
  "hash": "095a04c93492cf834844e9ea51065fbd",
  "result": {
    "markdown": "---\ntitle: \"Gradient Descent\"\ndate: \"2024-02-05\"\ncategories: ['data-science', 'tutorial-R', 'econometria']\ndescription: \"O algoritmo de Gradient Descent é um otimizador amplamente utilizado em Machine Learning para minimizar funções de custo. Este otimizador simples é baseado na direção do gradiente da função. Neste post explico a matemática que sustenta este método e mostro como implementá-lo passo a passo.\"\nexecute: \n  warning: false\n  message: false\n---\n\n\n\n\n# Entendendo o Gradiente Descent (GD)\n\nO Gradient Descent (GD), também conhecido como **steepest descent** ou até como Stochastic Gradient Descent (SGD)[^1], é um algoritmo fundamental em otimização que desempenha um papel crucial no ajuste de parâmetros de modelos de machine learning. Basicamente, o GD utiliza a informação do gradiente de uma função, que se quer otimizar, para encontrar o \"caminho\" em que ela decaí mais rapidamente.\n\n[^1]: Apesar dos métodos serem formalmente diferentes, a sua essência é idêntica a ponto de ser comum confundi-los. O SGD é uma \"aproximação\" do GD, onde apenas uma parte (amostra) dos dados é utilizada para calcular o gradiente. Neste sentido, o SGD é muito mais eficiente do ponto de vista computacional.\n\nNo caso mais típico, da minimização de uma função de perda, o GD ou SGD usa o gradiente da função para encontrar os valores dos parâmetros que minimizam esta função. O algoritmo opera iterativamente e, idealmente, aproxima-se gradualmente da solução correta.\n\nAssim, a utilidade geral do GD reside na sua capacidade de iterativamente encontrar o mínimo de funções usando relativamente pouca informação.\n\n## Regressão Simples\n\n### Um pouco de matemática\n\nPara tornar as coisas mais concretas vamos considerar o caso de uma regressão linear simples. Temos uma variável de resposta $y$ que será \"explicada\" por uma variável independente (feature) $x$ . A relação é modelada de maneira linear como:\n\n$$\ny = \\beta_{0} + \\beta_{1}x + \\varepsilon\n$$\n\nA equação acima descreve o nosso modelo, que será estimado posteriormente. Com este modelo podemos calcular os valores preditos $\\hat{y_{i}}$ que serão comparados com os valores observados (reais) $y_{i}$. Nosso objetivo é ajustar os parâmetros $\\beta_{0}$ e $\\beta_{1}$ para minimizar a função de custo, que pode ser representada como o Erro Quadrático Médio (MSE, do inglês *Mean Squared Error*):\n\n$$\n\\text{MSE} =  \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_{i}})^2= \\frac{1}{n} \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_1 X_i))^2\n$$\n\nPara atualizar os parâmetros $\\beta_0$ e $\\beta_1$ usando GD, precisamos calcular o gradiente da função de custo em relação a esses parâmetros. A primeira derivada da função de custo em relação a $\\beta_0$ e $\\beta_1$ nos dá as direções em que devemos ajustar esses parâmetros para minimizar a função de custo.\n\nA primeira derivada da função de custo em relação a $\\beta_0$ é dada por:\n\n$$\n\\frac{\\partial \\text{MSE}}{\\partial \\beta_0} = \\frac{-2}{n} \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_1 x_i))\n$$\n\nE a primeira derivada da função de custo em relação a $\\beta_1$ é dada por:\n\n$$\n\\frac{\\partial \\text{MSE}}{\\partial \\beta_1} = \\frac{-2}{n} \\sum_{i=1}^{n} x_i (y_i - (\\beta_0 + \\beta_1 x_i))\n$$\n\nEssas derivadas nos fornecem a direção em que devemos ajustar os parâmetros para minimizar a função de custo.\n\n### Implementando o algoritmo\n\nO algortimo de GD funciona iterativamente O algoritmo de SGD atualiza o parâmetro $\\beta^{t}$ a cada iteração t, onde $\\beta^{0}$ é dado, usando o gradiente $\\nabla_{\\beta}^t$ da seguinte maneira:\n\n$$\n\\beta^{t+1} = \\beta^{t} - \\gamma\\nabla_{\\beta}^{t}\n$$\n\nonde $\\gamma$ é um número real não-negativo, tipicamente próximo de 0.001, chamado \"learning rate\". Quanto maior for o valor de $\\gamma$ maiores serão os \"passos\" no processo de atualização; inversamente, quanto menor for o valor de $\\gamma$ menores serão os \"passos\"no processo iterativo.\n\nPara implementar o passo-a-passo do algoritmo vamos usar a base `mtcars`. O primeiro passo é ajustar os dados usando a função `scale`. Em seguida, separamos alguns objetos úteis para facilitar a exposição.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#> Regularizar os dados\nmtcars_scaled <- as.data.frame(scale(mtcars))\n\ny <- mtcars_scaled$mpg\nx <- mtcars_scaled$wt\nN <- nrow(mtcars_scaled)\n```\n:::\n\n\nVamos fazer a regressão de `mpg` (milhas por galão), uma medida da eficiência do veículo, contra `wt` (peso), o peso do veículo. Visualmente, parece haver uma relação linear decrescente entre as variáveis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(y ~ x)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nAntes de fazer o loop, vamos decompor o algoritmo em etapas. Primeiro, precisa-se de valores iniciais para os parâmetros $\\beta_{0}$ e $\\beta_{1}$. Por simplicidade, vamos sortear números aleatórios entre 0 e 1 a partir de uma distribuição uniforme. Com estes valores será possível calcular o valor de $\\hat{y}_{i}^0$, onde 0 indica que estamos na iteração de valor 0.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb0 <- runif(1)\nb1 <- runif(1)\n\n(yhat <- b0 + b1 * x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.6208543 0.7187999 0.5056241 0.8493942 0.9358168 0.9434988 0.9857499\n [8] 0.8397916 0.8244276 0.9358168 0.9358168 1.1778002 1.0472060 1.0664110\n[15] 1.6310390 1.6978725 1.6675286 0.4595320 0.2348331 0.3193352 0.5613187\n[22] 0.9665449 0.9338963 1.0894571 1.0913776 0.3577453 0.4364859 0.1956548\n[29] 0.8321096 0.6784694 0.9857499 0.6823104\n```\n:::\n:::\n\n\nNão é necessário, mas é instrutivo calcular a função de perda.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(mse <- mean((y - yhat)^2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.460318\n```\n:::\n:::\n\n\nAgora, calculamos o valor do gradiente neste ponto.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(gb0 <- sum(y - yhat) * (-2/N))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.700517\n```\n:::\n\n```{.r .cell-code}\n(gb1 <- sum((y - yhat) * x) * (-2/N))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.409253\n```\n:::\n:::\n\n\nPor fim, o valor dos parâmetros é atualizado segundo a fórmula matemática do algoritmo. Utiliza-se $g = 0.01$ como valor para a learning-rate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng = 0.01\n\n(b0_new <- b0 - g * gb0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8332532\n```\n:::\n\n```{.r .cell-code}\n(b1_new <- b1 - g * gb1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3517336\n```\n:::\n:::\n\n\nEste processo será repetido $T$ vezes até que se atinja algum critério de convergência. Em geral, estabelece-se\n\n1.  **Um número máximo de iterações**. (10.000 iterações, por exemplo).\n2.  **Um valor mínimo de mudança na estimativa dos parâmetros**. Isto é, quando o valor das estimativas para de mudar significativamente, entende-se que ele convergiu para um valor satisfatório.\n\nPara deixar o loop abaixo mais simples, vou simplesmente estabelecer um número máximo de 5000 iterações. O código segue abaixo. Note que algumas partes do código acima foram repetidas por conveniência da leitura.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_iterations <- 1000\n#> Learning-rate\ng <- 0.01\n\ny <- mtcars_scaled$mpg\nx <- mtcars_scaled$wt\nN <- nrow(mtcars_scaled)\n\n#> Valores iniciais para estimativas dos parâmetros\nb0 <- runif(1)\nb1 <- runif(1)\n\nfor (i in seq_len(num_iterations)) {\n\n  if (i %% 100 == 0) cat(\"Iteração: \", i, \"\\n\")\n\n  #> Calcula o valor previsto\n  yhat <- b0 + b1 * x\n\n  #> Calcula a \"função de perda\"\n  error <- y - yhat\n  mse <- mean(error^2)\n\n  if (i %% 100 == 0) {\n    cat(\"Valor da perda: \", as.numeric(mse), \"\\n\")\n  }\n\n  #> Calcula o gradiente nos pontos atuais\n  gb0 <- sum(y - yhat) * (-2/N)\n  gb1 <- sum((y - yhat) * x) * (-2/N)\n  #> Atualiza o valor dos parâmetros usando o gradiente\n  b0_new <- b0 - g * gb0\n  b1_new <- b1 - g * gb1\n\n  b0 <- b0_new\n  b1 <- b1_new\n\n  if (i %% 100 == 0) {\n    cat(\"Betas: \", c(b0, b1), \"\\n\\n\")\n  }\n\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIteração:  100 \nValor da perda:  0.2853807 \nBetas:  0.1032871 -0.6817206 \n\nIteração:  200 \nValor da perda:  0.2403345 \nBetas:  0.0136979 -0.8413769 \n\nIteração:  300 \nValor da perda:  0.2394606 \nBetas:  0.001816609 -0.8639443 \n\nIteração:  400 \nValor da perda:  0.2394436 \nBetas:  0.0002409179 -0.8671343 \n\nIteração:  500 \nValor da perda:  0.2394432 \nBetas:  3.195042e-05 -0.8675852 \n\nIteração:  600 \nValor da perda:  0.2394432 \nBetas:  4.237251e-06 -0.8676489 \n\nIteração:  700 \nValor da perda:  0.2394432 \nBetas:  5.619423e-07 -0.8676579 \n\nIteração:  800 \nValor da perda:  0.2394432 \nBetas:  7.452454e-08 -0.8676592 \n\nIteração:  900 \nValor da perda:  0.2394432 \nBetas:  9.883412e-09 -0.8676593 \n\nIteração:  1000 \nValor da perda:  0.2394432 \nBetas:  1.310735e-09 -0.8676594 \n```\n:::\n:::\n\n\nPara recuperar o valor final dos betas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc(b0, b1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  1.310735e-09 -8.676594e-01\n```\n:::\n:::\n\n\nPara efeito didático, vamos comparar estas estimativas finais contra os valores estimados pela função `lm`. Note que os valores estão muito similares\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model_lm <- lm(mpg ~ wt, data = mtcars_scaled))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars_scaled)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.75381 -0.39236 -0.02077  0.23388  1.14033 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.040e-15  8.934e-02   0.000        1    \nwt          -8.677e-01  9.077e-02  -9.559 1.29e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5054 on 30 degrees of freedom\nMultiple R-squared:  0.7528,\tAdjusted R-squared:  0.7446 \nF-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n```\n:::\n:::\n\n\n### Visualizando o processo\n\nSempre que possível, é útil visualizar o funcionamento do algoritmo em gráficos. Como estamos trabalhando com um exemplo simples, pode-se plotar os resultados gradativamente num gráfico de dispersão. O código abaixo mostra como a linha de ajuste (linha de regressão) vai se alterando à medida que se aumenta o número de amostras.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nnum_iterations <- 1000\n#> Learning-rate\nalpha <- 0.01\n\ny <- dat$mpg\nx <- dat$wt\nN <- nrow(dat)\n\n#> Valores iniciais para estimativas dos parâmetros\nb0 <- runif(1)\nb1 <- runif(1)\n\nbetas <- matrix(ncol = 2, nrow = num_iterations)\nfor (i in seq_len(num_iterations)) {\n\n  #> Calcula o valor previsto\n  yhat <- b0 + b1 * x\n\n  #> Calcula a \"função de perda\"\n  error <- y - yhat\n  mse <- mean(error^2)\n\n  #> Calcula o gradiente nos pontos atuais\n  gb0 <- sum(y - yhat) * (-2/N)\n  gb1 <- sum((y - yhat) * dat$wt) * (-2/N)\n  #> Atualiza o valor dos parâmetros usando o gradiente\n  b0_new <- b0 - alpha * gb0\n  b1_new <- b1 - alpha * gb1\n\n  b0 <- b0_new\n  b1 <- b1_new\n  \n  betas[i, 1] <- b0_new\n  betas[i, 2] <- b1_new\n\n\n}\n\nsel <- c(1:10, seq(20, 100, 10), seq(100, 1000, 50))\n\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(tibble)\n\ntbl_betas <- tibble(\n  iter = sel,\n  beta0 = betas[sel, 1],\n  beta1 = betas[sel, 2]\n)\n\nggplot() +\n  geom_point(\n    data = dat,\n    aes(x = wt, y = mpg),\n    shape = 21\n  ) +\n  geom_abline(\n    data = tbl_betas,\n    aes(intercept = beta0, slope = beta1),\n    color = \"#CB181D\",\n    lwd = 0.8\n  ) +\n  geom_text(\n    data = tbl_betas,\n    aes(x = 1.8, y = 1.8, label = paste(\"Iteration:\", iter)),\n    size = 5\n  ) +\n  transition_states(iter) +\n  enter_fade() + \n  exit_shrink() +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.gif)\n:::\n:::\n\n\n## Regressão Múltipla\n\nAgora vamos considerar o caso de regressão múltipla, onde temos várias variáveis independentes. A equação do modelo é generalizada para:\n\n$$\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_k x_k\n$$\n\nIsto é, agora temos $k$ variáveis independentes, $x_1, x_2, ..., x_k$, e temos $k$ coeficientes, $\\beta_0, \\beta_1, \\beta_2, ..., \\beta_k$, a ser estimados. A função de custo torna-se:\n\n$$\n\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_{1} x_{i1} + \\beta_2 x_{i2} + ... + \\beta_k X_{ik}))^2 \n$$\n\nAgora, as derivadas parciais da função de custo em relação a cada parâmetro $\\beta$ são calculadas e utilizadas para atualizar os coeficientes durante o GD.\n\n$$\n\\nabla_{\\beta} = (\\frac{\\partial\\text{MSE}}{\\partial\\beta_{0}}, \\frac{\\partial\\text{MSE}}{\\partial\\beta_{1}}, ..., \\frac{\\partial\\text{MSE}}{\\partial\\beta_{k}})\n$$\n\n### Regressão Múltipla com Matrizes\n\nNa regressão múltipla, podemos representar os dados de entrada $X$ e os parâmetros do modelo $\\beta$ como matrizes. Esta forma de representação é mais prática quando temos muitas variáveis e permite dispensar o uso de somatórios.\n\nSuponha que tenhamos $n$ observações e $k$ variáveis independentes.\n\nAs observações de entrada podem ser organizadas em uma matriz $X$ de dimensão $n \\times (k+1)$, onde a primeira coluna é composta por $1$s para representar o intercepto do modelo. Assim, a matriz $X$ é dada por:\n\n$$\nX = \\begin{bmatrix} \n1 & x_{11} & x_{12} & \\cdots & x_{1p} \\\\\n1 & x_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_{n1} & x_{n2} & \\cdots & x_{nk}\n\\end{bmatrix} \n$$\n\nOs parâmetros do modelo $\\beta$ podem ser representados como um vetor de coeficientes de dimensão $(k+1) \\times 1$. Assim, o vetor $\\beta$ é dado por:\n\n$$\n\\beta = \\begin{bmatrix} \n\\beta_0 \\\\\n\\beta_1 \\\\\n\\vdots \\\\\n\\beta_k\n\\end{bmatrix}\n$$\n\nA resposta $y$ pode ser representada como um vetor de dimensão $n \\times 1$.\n\n$$\ny = \\begin{bmatrix} \ny_0 \\\\\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix}\n$$\n\nNote que o problema de minimização acima é equivalente a minimizar a soma do erro ao quadrado do modelo. Isto acontece pois o erro, no caso mais simples, é simplesmente\n\n$$\n\\varepsilon = y_i - \\hat{y_i} = y_i - \\beta_{0} - \\beta_{1}x_i\n$$\n\ne o problema de minimizar:\n\n$$\n\\text{min } \\varepsilon^2 = (y_i - \\hat{y_i})^2\n$$\n\nEm termos matriciais temos:\n\n$$\ne = y - \\hat{y} = y - X\\beta\n$$ e agora o problema de minimizar\n\n$$\n\\text{min } e^te = (y - X\\beta)^t(y-XB) \n$$\n\nPara encontrar o gradiente da função de custo $e^te$, em relação aos parâmetros $\\beta$, podemos usar cálculo matricial.\n\nO gradiente $\\nabla_{\\beta} (e'e)$ é dado por:\n\n$$\n\\nabla_{\\beta} (e'e) = -2X^T(y - X\\beta)\n$$\n\nOnde $X^T$ representa a transposta da matriz X. Este gradiente nos fornece a direção em que devemos ajustar os (múltiplos) parâmetros $\\beta$ para minimizar a função de custo $e'e$.\n\n## Implementando o algoritmo\n\nDesta vez, vamos implementar tanto o gradiente como a função de perda como `function`s no `R`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrad <- function(beta) {\n\n  (2/N) * t(X) %*% (X %*% beta - y)\n\n}\n\nloss <- function(beta) {\n\n  e = y - X %*% beta\n\n  t(e) %*% e\n\n}\n```\n:::\n\n\n### O modelo\n\nNosso modelo de regressão agora terá a forma:\n\n$$\n\\text{mpg} = \\beta_{0} + \\beta_{1}\\text{wt} + \\beta_{2}\\text{qsec}+ \\beta_{3}\\text{am}\n$$\n\nonde `mpg` e `wt` tem as mesmas definições dadas acima; já `qsec` é uma medida de velocidade do veículo e `am` é uma variável binária que indica se o câmbio do veículo é manual ou automático.\n\n### Os dados\n\nDesta vez, o preparo dos dados será feito usando o pacote `dplyr`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\ndat <- mtcars |>\n  select(c(\"mpg\", \"wt\", \"qsec\", \"am\")) |>\n  mutate(across(everything(), ~as.numeric(scale(.x))))\n\ny <- dat$mpg\nX <- as.matrix(dat[, c(\"wt\", \"qsec\", \"am\")])\nX <- cbind(1, X)\ncolnames(X)[1] <- c(\"coef\")\nN <- nrow(X)\n```\n:::\n\n\n### Primeira iteração\n\nNovamente, para ganhar um pouco de intuição vamos rodar o\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#> Valor inicial para os betas\nbeta <- runif(ncol(X))\n\n# Opcional\n#> Computa a \"predição\" do modelo\nyhat <- X %*% beta\n#> Calcula o valor da função de perda\nl <- loss(beta)\n\n#> Atualiza o valor dos beta\nbeta_new <- beta - alpha * grad(beta)\n```\n:::\n\n\n### O loop completo\n\nO código abaixo mostra o loop completo. Fora algumas pequenas modificações, ele é exatamente igual ao loop anterior. Neste segundo exemplo, eu reduzo o valor da learning-rate e aumento o número de iterações.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nbeta <- runif(ncol(X))\nnum_iterations <- 10000\nalpha <- 0.001\n\nfor (i in seq_len(num_iterations)) {\n\n  if (i %% 1000 == 0) cat(\"Iteração: \", i, \"\\n\")\n\n  #> Calcula o valor previsto\n  yhat <- X %*% beta\n\n  #> Calcula a \"função de perda\"\n  vl_loss <- loss(beta)\n\n  if (i %% 1000 == 0) {\n    cat(\"Valor da perda: \", as.numeric(vl_loss), \"\\n\")\n  }\n\n  #> Calcula o gradiente nos pontos atuais\n  grad_current <- grad(beta)\n  #> Atualiza o valor dos parâmetros usando o gradiente\n  beta_current <- beta - alpha * grad_current\n\n  beta <- beta_current\n\n  if (i %% 1000 == 0) {\n    cat(\"Betas: \", beta, \"\\n\\n\")\n  }\n\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIteração:  1000 \nValor da perda:  7.13271 \nBetas:  0.03826274 -0.2251617 0.5673019 0.6576364 \n\nIteração:  2000 \nValor da perda:  5.758462 \nBetas:  0.005167938 -0.3615253 0.5036778 0.5224093 \n\nIteração:  3000 \nValor da perda:  5.157107 \nBetas:  0.0006980051 -0.4514262 0.4581729 0.4309751 \n\nIteração:  4000 \nValor da perda:  4.885259 \nBetas:  9.427573e-05 -0.511776 0.4272302 0.369487 \n\nIteração:  5000 \nValor da perda:  4.762206 \nBetas:  1.273331e-05 -0.5523671 0.4063727 0.3281235 \n\nIteração:  6000 \nValor da perda:  4.706502 \nBetas:  1.719818e-06 -0.579676 0.3923348 0.3002944 \n\nIteração:  7000 \nValor da perda:  4.681286 \nBetas:  2.322864e-07 -0.5980497 0.3828893 0.2815707 \n\nIteração:  8000 \nValor da perda:  4.669871 \nBetas:  3.137365e-08 -0.6104118 0.3765342 0.2689731 \n\nIteração:  9000 \nValor da perda:  4.664704 \nBetas:  4.237468e-09 -0.6187292 0.3722584 0.2604972 \n\nIteração:  10000 \nValor da perda:  4.662364 \nBetas:  5.72333e-10 -0.6243253 0.3693815 0.2547946 \n```\n:::\n:::\n\n\nPor fim, temos o valor final dos betas estimados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_current\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              [,1]\ncoef  5.723330e-10\nwt   -6.243253e-01\nqsec  3.693815e-01\nam    2.547946e-01\n```\n:::\n:::\n\n\nNovamente, podemos comparar estas estimativas com aquelas calculadas pela função `lm`. Note que, neste caso, mesmo após 10.000 iterações ainda há algumas pequenas divergências entre os valores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model_lm <- lm(mpg ~ wt + qsec + am, data = dat))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mpg ~ wt + qsec + am, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5776 -0.2581 -0.1204  0.2341  0.7734 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.485e-15  7.212e-02   0.000 1.000000    \nwt          -6.358e-01  1.155e-01  -5.507 6.95e-06 ***\nqsec         3.635e-01  8.559e-02   4.247 0.000216 ***\nam           2.431e-01  1.168e-01   2.081 0.046716 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.408 on 28 degrees of freedom\nMultiple R-squared:  0.8497,\tAdjusted R-squared:  0.8336 \nF-statistic: 52.75 on 3 and 28 DF,  p-value: 1.21e-11\n```\n:::\n:::\n\n\n## Conclusão\n\nO Gradiente Descendente é uma ferramenta poderosa para otimização em aprendizado de máquina e outros campos. Neste post, explicamos a matemática por trás do GD, mostramos como derivar o gradiente tanto para regressão linear simples quanto múltipla, e como entender o funcionamento deste algoritmo fundamental.\n\n# Posts relacionados\n\n-   [Estimação de Máxima Verossimilhança no R](https://restateinsight.com/posts/general-posts/repost-emv-no-r/)\n\n-   [OLS com matrizes no R](https://restateinsight.com/posts/general-posts/repost-ols-com-matrizes/)\n\n-   [Otimização numérica: métodos de Newton](https://restateinsight.com/posts/general-posts/repost-otimizacao-newton/)\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}