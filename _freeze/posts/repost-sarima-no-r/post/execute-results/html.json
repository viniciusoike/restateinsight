{
  "hash": "6555ca657f74e1e4b1d9e62a84900124",
  "result": {
    "markdown": "---\ntitle: \"SARIMA no R\"\ndate: '2019-03-20'\ncategories: ['econometria', 'series de tempo', 'repost', 'tutorial-r']\ndescription: \"Computando modelos SARIMA no R\"\ntitle-block-banner: true\nformat: \n  html:\n    fig-align: center\n    fig-dpi: 72\n    fig-format: svg\nexecute: \n  warning: false\n  message: false\n---\n\n\n# Introdução\n\nNeste post apresento como estimar um modelo SARIMA simples no R usando os pacotes `astsa` e `forecast`. O pacote `astsa` foi elaborado pelos autores do livro [Time Series Analysis](https://www.stat.pitt.edu/stoffer/tsa4/). Já o `forecast` foi desenvolvido por Rob. Hyndman, autor do livro [Forecasting: Principles and Practice](https://otexts.com/fpp2/).\n\n# O modelo\n\nO SARIMA adiciona sazonalidade estocástica multiplicativa ao modelo ARIMA. Lembre-se que o modelo ARMA(p,q) geral é da forma:\n\\begin{equation}\n  y_{t} = \\mu + \\phi_{1}y_{t-1} + \\phi_{2}y_{t-2} + \\dots + \\phi_{p}y_{t-p} + \\epsilon_{t} + \\theta_{1}\\epsilon_{t-1} + \\theta_{2}\\epsilon_{t-2} + \\dots + \\theta_{q}\\epsilon_{t-q}\n\\end{equation}\nPodemos reescrever a expressão acima usando o operador defasagem e os polinômios \n\\begin{align}\n\\phi(L) & = 1-\\phi_{1}L - \\phi_{2}L^{2} - \\dots - \\phi_{p}L^{p} \\\\\n\\theta(L) & = 1+\\theta_{1}L + \\theta_{2}L^{2} + \\dots + \\theta_{q}L^{q}\n\\end{align}\nAssim a expressão pode ser resumida como\n\\begin{equation}\n  \\phi(L)y_{t} = \\mu + \\theta(L)\\epsilon_{t}\n\\end{equation}\nO modelo ARIMA tira diferenças $d$ de $y_{t}$:\n\\begin{equation}\n  \\phi(L)(1-L)^{d}y_{t} = \\theta(L)\\epsilon_{t}\n\\end{equation}\nA princípio não há restrição sobre o valor de $d$ mas na prática sabemos que $d = 1$ ou $d = 2$.\nAgora vamos definir os polinômios sazonais: $\\Phi(L^{s}) = 1-\\Phi_{1}L^{s} - \\Phi_{2}L^{2s} - \\dots - \\Phi_{p}L^{Ps}$ e $\\Theta(L^{s}) = 1+\\Theta_{1}L^{s} + \\Theta_{2}L^{2s} + \\dots + \\Theta_{q}L^{Qs}$. Ou seja, digamos que a série $y_{t}$ seja mensurada mensalmente e apresente alguma sazonalidade anual. $y_{t}$ pode ser, por exemplo, a receita de vendas de uma empresa de varejo. É provável que a receita no mês de dezembro seja mais alta que a média do ano. Como isto se repete todo ano vamos encontrar um padrão anual nos dados que deve ser modelado. Neste exemplo, como $y_{t}$ é mensal temos que $s = 12$ nos polinômios sazonais. Logo teremos que:\n\\begin{align}\n  \\Phi(L)y_{t} & = 1 + \\Phi_{1}y_{t-12} + \\Phi_{2}y_{t-24} + \\dots + \\Phi_{p}y_{t-Ps}\\\\\n  \\Theta(L)\\epsilon_{t} & = 1+\\Theta_{1}\\epsilon_{t-12} + \\Theta_{2}\\epsilon_{t-24} + \\dots + \\Theta_{q}\\epsilon_{t-Qs}\n\\end{align}\nPodemos então montar modelos SARMA(p,q)(P,Q)[s]. Para tornar a notação mais clara vamos escrever o caso em que $y_{t} \\sim \\text{SARMA}(2,1)(1,3)[12]$\n\\begin{equation}\n  y_{t} = \\phi_{1}y_{t-1} + \\phi_{2}y_{t-2} + \\Phi_{1}y_{t-12} + \\epsilon_{t} + \\theta_{1}\\epsilon_{t-1} + \\Theta_{1}\\epsilon_{t-12} + \\Theta_{2}\\epsilon_{t-24} + \\Theta_{3}\\epsilon_{t-36}\n\\end{equation}\nDe forma geral, temos que:\n\\begin{equation}\n  \\Phi(L^{s})\\phi(L)y_{t} = \\mu + \\theta(L^{s})\\theta(L)\\epsilon_{t}\n\\end{equation}\nFinalmente, de forma análoga ao ARIMA, tiramos diferenças sazonais $D$ para chegar em:\n\\begin{equation}\n  \\Phi(L^{s})\\phi(L)(1-L)^{d}(1-L^{s})^{D}y_{t} = \\mu + \\theta(L^{s})\\theta(L)\\epsilon_{t}\n\\end{equation}\nAssim, como na análise do ARIMA o procedimento para identificação parte da comparação entre o correlograma empírico com as correlações teóricas do processo SARMA(p,q)(P,Q)[s]. Digamos, por exemplo, que a série de interesse $y_{t}$ siga um SARIMA(p,0,q)(P,1,Q). Então, temos que \n\n$$\nx_{t} = (1-L^{12})y_{t}\n$$\n\na série diferenciada sazonalmente, segue um SARMA(p,q)(P,Q). A partir das funções de autocorrelação e autocorrelação parcial de $x_{t}$ podemos tentar recuperar o verdadeiro valor de $p$, $q$, $P$ e $Q$.\n\n# Exemplo: passagens aéreas\n\nPrimeiro vamos carregar os pacotes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(astsa)    # acf2() e sarima()\nlibrary(forecast) # forecast() e autoplot()\nlibrary(ggplot2)  # carregar temas para a função autoplot()\n```\n:::\n\n\nVamos analisar o comportamento da demanda por passagens aéreas internacionais. Este é um exemplo clássico estudado em Box & Jenkins (1976). Esta séria apresenta tanto uma tendência de crescimento como uma clara sazonalidade.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(AirPassengers) +\n  geom_point(shape = 21) +\n  labs(x = \"\", y = \"Passagens aéreas (milhares)\", \n       title = \"Demanda mensal de passagens aéreas internacionais\", \n       caption = \"Fonte: Box & Jenkins (1976)\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](post_files/figure-html/unnamed-chunk-2-1.svg)\n:::\n:::\n\n\nUma maneira interessante de visualizar a sazonalidade da série é \"empilhando\" os ciclos. No caso, parece haver uma sazonalidade que se repete a cada ano. A função `ggseasonplot` do pacote `forecast` facilita esta visualização. Os meses de junho, julho e agosto parecem sempre ter valores mais elevados. De fato, estes são os meses do verão no hemisfério norte e da alta estação do turismo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Gráfico mensal\nggseasonplot(AirPassengers) +\n  ggtitle(\"Sazonalidade\") +\n  labs(x = \"\") +\n  scale_colour_discrete(name = \"Ano\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](post_files/figure-html/unnamed-chunk-3-1.svg)\n:::\n:::\n\n\n## Identificação e tranformações\n\nComo a variância da série cresce ao longo do tempo aplico uma transformação log nos valores da série. Seja $y_{t}$ nossa série. Então fazemos $ly_{t} \\equiv \\text{log}(y_{t}).$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Aplica transformação log (logaritmo natural)\nly <- log(AirPassengers)\n# Gráfico\nautoplot(ly) +\n  geom_point(shape = 21) +\n  labs(x = \"\",\n       y = \"Passagens aéreas (log)\",\n       title = \"Demanda mensal de passagens aéreas internacionais\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](post_files/figure-html/unnamed-chunk-4-1.svg)\n:::\n:::\n\n\nPara testar a acurácia do modelo vamos remover algumas das últimas observações. Estas serão testadas contra as previsões do modelo. Aqui sigo a nomenclatura de *train* (treino) e *test* (teste). O gráfico abaixo permite visualizar esta divisão, onde os valores em vermelho foram excluídos da nossa amostra.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain <- window(ly, end = c(1957, 12))\ntest <- window(ly, start = c(1958, 1))\n\nautoplot(train) +\n  autolayer(test) +\n  theme_bw() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](post_files/figure-html/unnamed-chunk-5-1.svg)\n:::\n:::\n\n        \nTirando a primeira diferença da série removemos a sua tendência de crescimento. Fazemos $dly_{t} \\equiv (1-L)ly_{t} = ly_{t} - ly_{t-1}$ usando a função `diff()`. Note pelo gráfico que ainda parece haver forte sazonalidade na série.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tira a primeira diferença da série\ndly <- diff(train)\n\nautoplot(dly) +\n  ggtitle(\"Primeira diferença do log da série\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](post_files/figure-html/unnamed-chunk-6-1.svg)\n:::\n:::\n\n\nPodemos ver isto mais claramente na análise do correlograma da série diferenciada. No gráfico abaixo, os \"lags\" seguem a periodicidade da série, isto é, cada \"lag\" representa o equivalente a 12 meses. Parece haver uma forte correlação entre $dly_{t}$ com $dly_{t-12}, dly_{t-24}, \\dots, dly_{t-12k}$ com $k = 1, 2, \\dots$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Gráfico da FAC e FACP\nacf2(dly)\n```\n\n::: {.cell-output-display}\n![](post_files/figure-html/unnamed-chunk-7-1.svg)\n:::\n:::\n\n\nAgora tiramos uma diferença sazonal de 12 meses. A série resultante, $sdly_{t}$ fica:\n\\begin{align}\n  sdly_{t} \\equiv (1-L^{12})dly_{t} & = (1-L^{12})(1-L)ly_{t} \\\\\n                                    & = (1 - L^{12} - L + L^{13})ly_{t} \\\\\n                                    & = ly_{t} - ly_{t-1} - ly_{t-12} + ly_{t-13}\n\\end{align}\n\nAbaixo temos o correlograma de $sdly_{t}$. A primeira defasagem é significativa tanto no ACF como no PACF. Além disso a 12ª defasagem também é significativa em ambos. Assim, vamos primeiro tentar um modelo de \"ordem máxima\" SARIMA$(1,1,1)(1,1,1)[12]$. A partir deste modelo, vamos tentar estimar outros de ordens mais baixas para evitar o problema de sobreparametrização.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tira a primeira diferença sazonal da série\nsdly <- diff(dly, 12)\n# Gráfico da FAC e FACP\nacf2(sdly)\n```\n\n::: {.cell-output-display}\n![](post_files/figure-html/unnamed-chunk-8-1.svg)\n:::\n:::\n\n\n## Estimação\n\nA equação do modelo que estamos estimando é:\n$$\n  (1 - \\phi L)(1 - \\Phi L^{12})(1 - L)(1 - L^{12})ly_{t} = (1 + \\theta L)(1 + \\Theta L^{12})\\epsilon_{t}\n$$\nVamos o usar o comando `sarima` do pacote `astsa`. Note que os resíduos do modelo parecem se comportar como ruído branco, indicando que nosso modelo está bem ajustado.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(m1 <- sarima(p = 1, d = 1, q = 1, P = 1, D = 1, Q = 1, S = 12, xdata = train))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ninitial  value -3.031632 \niter   2 value -3.170590\niter   3 value -3.246467\niter   4 value -3.246688\niter   5 value -3.247295\niter   6 value -3.247539\niter   7 value -3.247841\niter   8 value -3.248283\niter   9 value -3.248794\niter  10 value -3.249345\niter  11 value -3.249360\niter  12 value -3.249378\niter  13 value -3.249379\niter  14 value -3.249380\niter  15 value -3.249381\niter  16 value -3.249381\niter  17 value -3.249381\niter  17 value -3.249381\niter  17 value -3.249381\nfinal  value -3.249381 \nconverged\ninitial  value -3.248923 \niter   2 value -3.252561\niter   3 value -3.258267\niter   4 value -3.265627\niter   5 value -3.267071\niter   6 value -3.267585\niter   7 value -3.267745\niter   8 value -3.268029\niter   9 value -3.268401\niter  10 value -3.268494\niter  11 value -3.268499\niter  12 value -3.268506\niter  13 value -3.268511\niter  14 value -3.268511\niter  15 value -3.268511\niter  15 value -3.268511\niter  15 value -3.268511\nfinal  value -3.268511 \nconverged\n```\n:::\n\n::: {.cell-output-display}\n![](post_files/figure-html/unnamed-chunk-9-1.svg)\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n$fit\n\nCall:\narima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), \n    include.mean = !no.constant, transform.pars = trans, fixed = fixed, optim.control = list(trace = trc, \n        REPORT = 1, reltol = tol))\n\nCoefficients:\n         ar1      ma1     sar1     sma1\n      0.2565  -0.6243  -0.0599  -0.5574\ns.e.  0.2759   0.2289   0.1765   0.1670\n\nsigma^2 estimated as 0.001367:  log likelihood = 175.71,  aic = -341.42\n\n$degrees_of_freedom\n[1] 91\n\n$ttable\n     Estimate     SE t.value p.value\nar1    0.2565 0.2759  0.9299  0.3549\nma1   -0.6243 0.2289 -2.7271  0.0077\nsar1  -0.0599 0.1765 -0.3392  0.7353\nsma1  -0.5574 0.1670 -3.3380  0.0012\n\n$AIC\n[1] -3.593882\n\n$AICc\n[1] -3.589203\n\n$BIC\n[1] -3.459467\n```\n:::\n:::\n\n\nPara evitar o problema de sobreparametrização (*overfitting*) temos que tentar ajustar modelos de ordens similares, porém mais baixas. Este processo costuma ser iterativo, isto é, na base da tentativa e erro seguindo algum critério de informação (i.e.: AIC, AICc, BIC, etc.). Depois de tentar vários modelos diferentes chegamos, por exemplo, no SARIMA$(0,1,1)(0,1,1)[12]$. A equação do modelo pode ser expressa como:\n$$\n  (1 - L)(1 - L^{12})ly_{t} = (1 + \\theta L)(1 + \\Theta L^{12})\\epsilon_{t}\n$$\n\nNovamente, os resíduos do modelo indicam que ele está bem ajustado aos dados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- sarima(p = 0, d = 1, q = 1, P = 0, D = 1, Q = 1, S = 12, xdata = train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ninitial  value -3.047456 \niter   2 value -3.251231\niter   3 value -3.251514\niter   4 value -3.268396\niter   5 value -3.270049\niter   6 value -3.270196\niter   7 value -3.270197\niter   8 value -3.270198\niter   8 value -3.270198\niter   8 value -3.270198\nfinal  value -3.270198 \nconverged\ninitial  value -3.263453 \niter   2 value -3.264133\niter   3 value -3.264159\niter   4 value -3.264160\niter   4 value -3.264160\niter   4 value -3.264160\nfinal  value -3.264160 \nconverged\n```\n:::\n\n::: {.cell-output-display}\n![](post_files/figure-html/unnamed-chunk-10-1.svg)\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm2$fit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\narima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), \n    include.mean = !no.constant, transform.pars = trans, fixed = fixed, optim.control = list(trace = trc, \n        REPORT = 1, reltol = tol))\n\nCoefficients:\n          ma1     sma1\n      -0.3864  -0.5885\ns.e.   0.1097   0.0927\n\nsigma^2 estimated as 0.001383:  log likelihood = 175.3,  aic = -344.59\n```\n:::\n:::\n\n\nA estimativa tem a forma:\n\n$$\n  (1 - L)(1 - L^{12})ly_{t} = (1 - 0.3864 L)(1 - 0.5885 L^{12})\\epsilon_{t}\n$$\n\n## Previsão\n\nPara computar as previsões do modelo usamos a função `sarima.for`. Aqui podemos comparar as previsões do modelo (construindo usando apenas as observações dentro de *train*) com as observações. Esta função automaticametne retorna um gráfico com as previsões fora da amostra.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred <- sarima.for(train, n.ahead = length(test),\n                   p = 0, d = 1, q = 1, P = 0, D = 1, Q = 1, S = 12)\n```\n\n::: {.cell-output-display}\n![](post_files/figure-html/unnamed-chunk-12-1.svg)\n:::\n:::\n\n\nPodemos construir um gráfico que inclui as observações reservadas no *test* usando as seguintes funções base do R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot.ts(pred$pred, col = \"red\", ylim = c(5.7, 6.5),\n        ylab = \"\",\n        main = \"Previsão do modelo SARIMA(0, 1, 1)(0, 1, 1)[12]\")\nlines(test, type = \"o\")\nlegend(\"topleft\", legend = c(\"Previsto\", \"Observado\"), lty = 1,\n       pch = c(NA, 1), col = c(\"red\", \"black\"))\n```\n\n::: {.cell-output-display}\n![](post_files/figure-html/unnamed-chunk-13-1.svg)\n:::\n:::\n\n\n        \nComo comentado em outro post, pode-se produzir visualizações mais elegantes usando o `ggplot2`, mas o pacote não \"conversa\" bem com os objetos típicos de séries de tempo. Um jeito de contornar isto é usando a função `autoplot()` do pacote `forecast`. Abaixo, reestimo o modelo usando a função `arima`. Este passo é necessário para usar a função `autoplot()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- arima(train, order = c(0, 1, 1), seasonal = list(order = c(0, 1, 1), period = 12))\n```\n:::\n\n\nAgora podemos verificar a qualidade das nossas previsões. O gráfico abaixo foi construído funções base do R. A linha azul representa as previsões do modelo SARIMA especificado acima, enquanto que a linha vermelha representa as observações. As áreas sombreadas são intervalos de confiança: o mais escuro é de 80% e o mais claro de 95%. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(forecast(m, h = length(test)))\nlines(test, col = \"black\")\nlegend(\"topleft\",\n       legend = c(\"Previsto\", \"Observado\"),\n       lty = 1, col = c(\"red\", \"black\"))\n```\n\n::: {.cell-output-display}\n![](post_files/figure-html/unnamed-chunk-15-1.svg)\n:::\n:::\n\n\nUsando o autoplot temos o seguinte resultado:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(forecast(m, h = length(test)), include = 50) +\n  autolayer(test) +\n  labs(x = \"\", y = \"\") + \n  theme_bw() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](post_files/figure-html/unnamed-chunk-16-1.svg)\n:::\n:::\n\n\n# Conclusão\n\nOs modelos SARIMA são uma extensão aos modelos ARIMA que acrescentam um componente sazonal nos dados. O exemplo acima mostrou uma série com frequência mensal, mas a mesma lógica se aplica a séries com sazonalidade semestral, trimestral, etc.\n\nEstes modelos geram boas previsões e são fáceis de estimar o que explica a sua popularidade.\n",
    "supporting": [
      "post_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}