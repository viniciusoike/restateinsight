---
title: "The Greatest Films of All-time: a data approach"
date: "2024-04-17"
categories: ['data-visualization', 'ggplot2', 'movies', 'english']
description: "In this post I delve into the data to try to visualize patterns in movies rankings. Are movie critics biased towards a certain period of cinema? Are new movies overrated? Are they underrated? Movie rankings created by critics and the public show clear differences. Critics' lists tend to be quite consistent and often favor older films. In contrast, rankings based on public online votes generally give more weight to recent films."
execute: 
  message: false
  warning: false
  echo: false
---

```{r}
#| include: false
knitr::opts_chunk$set(fig.align = "center", out.width = "90%")
```

# Movie rankings

While some find it odd to rank movie tastes, I've always enjoyed "greatest of all times" lists. When not taken too literally, these lists provide a resourceful almanac of good movies, including classics, and culturally relevant movies. By construction, these lists will always be lacking and always be biased: it's a subjective evaluation of the best of the best films after all.

**Traditionally, these lists were penned by movie critics or experts**; more recently, however, there are several "greatest of all times" lists voted by the public. Perhaps the most well known of these is the Top 250 IMDB. As of December 2024, the top 250 films alone aggregate almost 180 million votes.

When comparing these lists, the ones made by critics and those voted by the broader public, one notices a kind **"temporal bias" in the rankings**. New movies, released in the past 10-15 years, rarely appear in prestigious lists such as the **BFI's Greatest Films**. In fact, in it's most recent edition, published in 2022, **only 24 of the 264 films were released in the 21st Century (less than 10%)**. On the flip side, online rankings such as the **Top 250 IMDB are flooded with new releases**. Almost **36% of the films featured in the Top 250 IMDB were released from 2001 to 2021**.

In this post I delve into the data to try to visualize these patterns. Are movie critics biased towards a certain period of cinema? Are new movies overrated? Are they underrated?

## Rankings

There are several "greatest movies of all time" lists. **Comparing them directly is often impossible due to conflicting methodologies**. For simplicity, I'll delve mostly into the Top 250 IMDB and the BFI Greatest Films of All Time. IMDB's ranking compiles the largest number of online votes and has a [relatively sturdy methodology for both its ratings and its rankings](https://help.imdb.com/article/imdb/track-movies-tv/ratings-faq/G67Y87TFYYP6TWAV?showReportContentLink=false&recentlyAuthenticated=true#). The BFI list compiles votes from academics, critics, curators, archivists, and programmers. Its most recent edition was published in 2022.

The lists are relatively comparable in size: IMDB's has (obviously) 250 films while BFI's has 264. While BFI's list has ties, I ignore these to make comparisons simpler.

In a latter part of the post I extend the analysis to other lists published by media outlets such as Variety and TimeOut and also to other online sites such as Letterboxd.

### The data

Getting all the data involves a lot of webscraping. More information on the data collection process can be found on [my Github](https://github.com/viniciusoike/restateinsight/blob/main/static/data-raw/R/greatest_movie_lists.R).

```{r}
library(ggplot2)
library(ggdist)
library(dplyr)
library(tidyr)
library(showtext)
font_add_google("Raleway", "Raleway")
showtext_auto()

films <- qs::qread(here::here("static/data/greatest_movies.qs"))

dict <- tribble(
  ~source, ~list_type,
  "afi", "critics",
  "bfi", "critics",
  "ebert", "critics",
  "empire", "public",
  "variety", "critics",
  "timeout", "critics",
  "bbc_american", "critics",
  "bbc_women", "critics",
  "bbc_foreign", "critics",
  "bbc_21st", "critics",
  "imdb", "public",
  "rolling_stones_scifi", "critics",
  "letterboxd", "public",
  "criticker", "public"
)

films <- left_join(films, dict, by = "source")
```

## Critics vs Public

### Recency bias?

Looking at the data by decade seems to reveal a clear pattern. BFI's list peaks around the 1960's, while IMDB's list peaks around the 2000's. There's a small bump in the 1950's but nothing noteworthy.

```{r}
imdb <- filter(films, source == "imdb")
```

```{r}
films <- films |> 
  mutate(decade = year - (year %% 10))

imdb <- filter(films, source == "imdb")

imdb_count <- count(imdb, decade)

p1 <- ggplot(imdb_count, aes(decade, n)) +
  geom_col(fill = "#deb522") +
  geom_text(aes(y = n - 3, label = n), family = "Raleway") +
  geom_hline(yintercept = 0) +
  scale_x_continuous(
    breaks = seq(1910, 2020, 10),
    labels = \(x) paste0(substr(x, 3, 4), "'s"),
    limits = c(1910, NA)) +
  labs(
    subtitle = "IMDB Top 250 (voted by general online public)",
    x = NULL,
    y = NULL
  ) +
  theme_minimal(base_family = "Raleway") +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank()
  )

bfi <- filter(films, source == "bfi")

bfi_count <- count(bfi, decade)

p2 <- ggplot(bfi_count, aes(decade, n)) +
  geom_col(fill = "#2166ac") +
  geom_text(aes(y = n - 3, label = n), family = "Raleway", color = "white") +
  geom_hline(yintercept = 0) +
  scale_x_continuous(
    breaks = seq(1910, 2020, 10),
    labels = \(x) paste0(substr(x, 3, 4), "'s")) +
  labs(
    subtitle = "BFI Greatest Films (voted by movie critics)",
    x = NULL,
    y = NULL
  ) +
  theme_minimal(base_family = "Raleway") +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank()
  )

library(patchwork)

panel <- p1 / p2

final_plot <- panel + plot_annotation(
  title = "The Greatest Films of All Time: critics x public",
  subtitle = "Year of release of the 250 'greatest films of all time' by decade.",
  caption = "Source: IMDB (IMDB Top 250, April 2024), BFI (The Greatest Films of All Time, 2022)") &
  theme(
    plot.margin = margin(5, 10, 5, 10, "pt"),
    plot.title = element_text(
      size = 18,
      family = "Raleway",
      margin = margin(5.5, 0, 5.5, 10)),
    plot.subtitle = element_text(
      size = 12,
      color = "gray20",
      family = "Raleway",
      margin = margin(2, 0, 5.5, 10)),
    plot.caption = element_text(
      family = "Raleway",
      size = 10,
      color = 'gray30'
    ),
    axis.text.x = element_text(size = 12)
  )
```

```{r}
final_plot
```

```{r}
tab <- inner_join(
  select(bfi, name_film, rank_bfi = rank), 
  select(imdb, name_film, rank_imdb = rank),
  by = "name_film"
  )

comp <- tab |> 
  mutate(
    diff = rank_bfi - rank_imdb,
    abs_diff = abs(diff),
    name_film = if_else(
      stringr::str_detect(name_film, "^Dr\\. Strangelove"),
      "Dr. Strangelove",
      name_film,
    ),
    name_film = factor(name_film),
    name_film = forcats::fct_reorder(name_film, -abs_diff),
    is_critics = factor(if_else(diff < 0, 1L, 0L))) |> 
  arrange(desc(diff)) |> 
  filter(abs_diff > 100 | abs_diff < 50)

comp_long <- comp |> 
  tidyr::pivot_longer(cols = rank_bfi:rank_imdb)
```

```{r}
tab1 <- comp |> 
  filter(abs_diff < 50) |> 
  mutate(name_film = forcats::fct_reorder(name_film, rank_bfi)) |> 
  arrange(name_film)

tab1_long <- tab1 |> 
  tidyr::pivot_longer(cols = rank_bfi:rank_imdb) |> 
  mutate(
    is_bfi = if_else(stringr::str_detect(name, "rank_bfi"), 1L, 0L),
    is_bfi = factor(is_bfi)
    )
```

While one could argue that IMDB's ranking suggests some level of *recency bias* among the public, the numbers might also be a reflection of (1) the age demographic of online voters; (2) the (lack of) availability of older films, specially in mainstream streaming services.

### Convergence

Going into greater details reveals some curious features about how these lists compare. Some films appear to be appreciated by both the public and the critics. Films like Kurosawa's Seven Samurai, Hitchcock's Psycho, and Coppola's The Godfather all rank highly in both lists.

There are, of course, divergences: some films, like Metropolis (1927) and The Apartment (1960) are slightly favored by the BFI's critics; meanwhile, Ran (1985) and Modern Times (1936) are favored by the public. These divergences don't seem to correlate directly with the year of release of each movie or even with its director.

Its important to note that rankings work in a counter-intuitive fashion to most graphics, since the best (highest-ranking) films are associated with lower numbers and appear on the left. To make reading the graphics easier, colors and symbols were used to identify which films ranked higher on each list.

```{r}
colors <- c("#deb522", "#2166ac")

ggplot(tab1) +
  geom_segment(
    aes(x = name_film, xend = name_film, y = rank_bfi, yend = rank_imdb)
  ) +
  geom_point(
    data = tab1_long,
    aes(x = name_film, y = value, color = is_bfi),
    size = 2
  ) +
  geom_point(
    data = tab1,
    aes(x = name_film, y = -10, shape = is_critics, color = is_critics),
    size = 2
  ) +
  geom_curve(
    data = data.frame(x = "Mad Max: Fury Road", xend = "Mad Max: Fury Road", y = -8, yend = 20),
    aes(x = x, xend = xend, y = y, yend = yend),
    curvature = -0.45,
    linewidth = 0.1,
    arrow = arrow(length = unit(0.01, "npc"))
    ) +
  geom_curve(
    data = data.frame(x = "Raging Bull", xend = "Raging Bull", y = -8, yend = 20),
    aes(x = x, xend = xend, y = y, yend = yend),
    curvature = -0.45,
    linewidth = 0.1,
    arrow = arrow(length = unit(0.01, "npc"))
  ) +
  annotate(
    "label",
    x = "Ran",
    y = 20,
    label = "Yellow triangles\nindicate films\nfavored by the public",
    label.size = 0,
    size = 2,
    family = "Raleway"
  ) +
  annotate(
    "label",
    x = "There Will Be Blood",
    y = 20,
    label = "Blue triangles\nindicate films\nfavored by the critics",
    label.size = 0,
    size = 2,
    family = "Raleway"
  ) +
  annotate(
    "label",
    x = "Psycho",
    y = 80,
    label = "Psycho is acclaimed\nby both audiences\nand critics.",
    label.size = 0,
    size = 2,
    family = "Raleway"
  ) +
  annotate(
    "label",
    x = "Metropolis",
    y = 150,
    label = "Metropolis is more\ncritics-favored.",
    label.size = 0,
    size = 2,
    family = "Raleway"
  ) +
  annotate(
    "label",
    x = "Raging Bull",
    y = 190,
    label = "Ran is more\nfavored by the public.",
    label.size = 0,
    size = 2,
    family = "Raleway"
  ) +
  scale_x_discrete(labels = \(x) stringr::str_wrap(x, 18)) +
  scale_y_continuous(breaks = c(1, seq(50, 250, 50))) +
  scale_color_manual(
    name = "",
    values = colors,
    labels = c("IMDB", "BFI")
  ) +
  scale_shape_manual(values = c(2, 6)) +
  guides(shape = "none") +
  coord_flip() +
  labs(
    title = "",
    subtitle = "Samples of movies ranked by BFI x IMDB\n\n",
    x = NULL,
    y = "Rank (less is higher)"
  ) +
  theme_minimal(base_family = "Raleway", base_size = 10) +
  theme(
    legend.position = c(0.08, 1.05),
    legend.direction = "horizontal",
    axis.text.y = element_text(hjust = 1)
  )

```

```{r}
tab2 <- comp |> 
  filter(abs_diff > 100) |> 
  mutate(name_film = forcats::fct_reorder(name_film, -rank_bfi)) |> 
  arrange(name_film)

tab2_long <- tab2 |> 
  tidyr::pivot_longer(cols = rank_bfi:rank_imdb) |> 
  mutate(
    is_bfi = if_else(stringr::str_detect(name, "rank_bfi"), 1L, 0L),
    is_bfi = factor(is_bfi)
    )
```

### Divergence

Looking even deeper into the discrepancies between the lists reveals an interesting trend. The movies on the top of the plot are overwhelmingly favored by the critics: these include Tokyo Story, Citizen Kane, Barry Lyndon, and The Third Man. Movies more to the bottom of the list are favorites of the public, including: Raiders of Lost Ark, The Matrix, Star Wars - New Hope, and Pulp Fiction.

While year of release seems to play a significant role, one can also theorize that the content of these films plays a much larger one.

```{r}
colors <- c("#deb522", "#2166ac")

ggplot(tab2) +
  geom_segment(
    aes(x = name_film, xend = name_film, y = rank_bfi, yend = rank_imdb)
    ) +
  geom_point(
    data = tab2_long,
    aes(x = name_film, y = value, color = is_bfi),
    size = 2
  ) +
  geom_point(
    data = tab2,
    aes(x = name_film, y = -10, shape = is_critics, color = is_critics),
    size = 2
  ) +
  annotate(
    "label",
    x = "Citizen Kane",
    y = 170,
    label = "Tokyo Story is the most 'divisive' movie.\nRanked 4th by the BFI and 211th by IMDB.",
    label.size = 0,
    size = 2,
    family = "Raleway"
  ) +
  scale_x_discrete(labels = \(x) stringr::str_wrap(x, 22)) +
  scale_y_continuous(breaks = c(1, seq(50, 250, 50))) +
  scale_color_manual(
    name = "",
    values = colors,
    labels = c("IMDB", "BFI")
    ) +
  scale_shape_manual(values = c(2, 6)) +
  guides(shape = "none") +
  coord_flip() +
  labs(
    title = "",
    subtitle = "Samples of movies ranked by BFI x IMDB\n\n",
    x = NULL,
    y = "Rank (less is higher)"
  ) +
  theme_minimal(base_family = "Raleway", base_size = 10) +
  theme(
    legend.position = c(0.08, 1.05),
    legend.direction = "horizontal",
    axis.text.y = element_text(hjust = 1)
  )
```

Finally, it's also important to note movies that appear exclusively in one list. These last two tables more clearly reflect the difference between critically appraised movies and favorites of the public.

The best ranking films in BFI's list that don't appear at all in IMDB's list include The Rules of the Game (1939), Persona (1966), and Mulholland Drive (2001). This is definitely a very snobish list, but again, year of release doesn't seem to matter much.

```{r}
library(gt)
tab <- full_join(
  select(bfi, name_film, year, rank_bfi = rank), 
  select(imdb, name_film, year, rank_imdb = rank),
  by = "name_film"
  )

tab |> 
  filter(is.na(rank_imdb)) |> 
  slice_min(rank_bfi, n = 15) |> 
  select(name_film, year.x, rank = rank_bfi) |> 
  gt(caption = "Highest ranked BFI films not appearing on IMDB") |> 
  cols_label(
    name_film = "Name",
    year.x = "Year",
    rank = "Rank (BFI)"
  )

```

The best ranking films in IMDB's list that don't appear at all in BFI's list include The Lord of the Rings trilogy (2001-2003), The Shawshank Redemption (1994), and several Christopher Nolan movies. Outside of Lumet's 12 Angry Men (1957) most of this list heavily skewed to the 1990's onwards.

```{r}
tab |> 
  filter(is.na(rank_bfi)) |> 
  slice_min(rank_imdb, n = 15) |> 
  select(name_film, year.y, rank = rank_imdb) |> 
  gt(caption = "Highest ranked IMDB films not appearing on BFI") |> 
  cols_label(
    name_film = "Name",
    year.y = "Year",
    rank = "Rank (IMDB)"
  )
```

## Critics x Public - 2

```{r}
sources <- c(
  "criticker", "letterboxd", "imdb", "empire", "afi", "bfi", "timeout", "variety"
  )

labels_sources <- c(
  "Top 250 Criticker", "Top 250 Letterboxd", "IMDb Top 250", "Empire 500 Greatest Movies",
  "AFI 100 Greatest Films", "BFI Greatest Films", "TimeOut Top 100", "Variety Top 100"
)

films_selection <- films |> 
  filter(
    year > 1900,
    year <= 2020,
    source %in% sources
  ) |> 
  mutate(
    source = factor(source, levels = sources, labels = labels_sources)
  )
```

Gathering data from other sources reveals more curious patterns. The plot below aggregates data from 8 different rankings: four of them voted by critics and four of them voted by the public[^1]. The latter are online polls voted by users and for simplicity are all shown in yellow; the former are polls voted by experts and critics and are shown in blue.

[^1]: To be fair, Empire's list combines both critics and general public. The numbers however, skew it toward the public.

```{r}
#| out-width: '100%'
#| fig-width: 9
df_decade <- tibble(
  x = seq(1940, 2000, 20),
  y = 1,
  label = paste0(x, "'s")
)

p_compare <- ggplot(films_selection, aes(x = year)) +
  geom_dots(aes(fill = list_type), linewidth = 0.1, dotsize = 1) +
  geom_text(
    data = df_decade,
    aes(x = x + 5, y = y, label = label),
    angle = 90,
    size = 3,
    family = "Raleway"
  ) +
  facet_wrap(vars(source), ncol = 4) +
  scale_x_continuous(breaks = seq(1930, 2010, 10)) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 1.15)) +
  geom_hline(yintercept = 0) +
  geom_vline(
    xintercept = seq(1940, 2000, 20),
    linetype = 2,
    color = "gray30"
  ) +
  scale_fill_manual(values = rev(colors)) +
  scale_color_manual(values = rev(colors)) +
  guides(fill = "none", color = "none") +
  labs(
    title = "The greatest films of all time over the decades: critics x public",
    subtitle = "Each dot represents a movie",
    x = "Year of Release",
    y = NULL
  ) +
  theme_minimal(base_family = "Raleway") +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_line(linetype = 2),
    panel.grid.major.y = element_blank(),
    axis.text.y = element_blank(),
    axis.text.x = element_text(angle = 90)
  )

p_compare
```

All four lists organized by critics present similar characteristics. They are shaped almost like a triangle with its vertex somewhere around the 1960's with a small outlier peak in the late 1990's. AFI's ranking differs slightly from this pattern exhibiting a relatively larger peak in the 1940's.

The rankings voted by the public are much more scattered. Criticker's ranking is the most similar to the critics'. It has a large share of films in the late 1940's and 1950's, but fewer in the 1960's and 70's relative to the critics.

IMDB's ranking, as seen previously, is heavily skewed to right, with several films from the 1990's and 2000's. Empire's ranking is similar in shape to IMDB's, almost resembling a ladder that peaks in 1999.

Finally, Letterboxd's list seems to be a mixture of Criticker's 1950's bias with IMDB's 1990's bias.

### Lists inside lists

Similarly to the BFI x IMDB comparison, these lists aren't directly comparable. Most importantly, they were (1) published at different times[^2]; and (2) have different sample sizes[^3].

[^2]: The Criticker (2022), Letterboxd (2022), IMDB (2024), TimeOut (2024), BFI (2022), and Variety (2022) lists are relatively comparable among themselves. Empire's ranking was published in 2008. AFI's ranking is more recent but doesn't include films released after the 2000's.

[^3]: For some reason 250, and its multiples, is a favorite among the public and 100 is preferred by the critics.

A simple way to compare the similarity between these lists is to count the overlaps in films. That is, how many films in list A are present in list B. To overcome the differences in sample size, I truncate the larger list by the smaller list size. When comparing, for instance, the Variety Top 100 with the IMDB Top 250, I simply truncate the IMDB list at 100.

This should work well for most comparisons except for AFI and Empire. AFI's ranking lists only American movies up to 2000; and Empire ranks movies only up until 2008.

The plot below shows this simple measure of overlap where the number represents the percentage of overlap between a pair of lists. This means that 64.9% of the films listed on Criticker also appear on Letterboxd's Top 250.

```{r}
compare_vectors <- function(x, y) {
  
  x1 <- x$name_film
  x2 <- y$name_film
  
  if (length(x1) >= length(x2)) {
    sum(x2 %in% x1[1:length(x2)]) / length(x2)
  } else {
    sum(x1 %in% x2[1:length(x1)]) / length(x1)
  }
  
  # sum(x2 %in% x1) / length(x2)
  # gespeR::rbo(x1, x2)
  # intersect(x1, x2) / length(x2)
  
  # if (length(x1) > length(x2)) {
  #   rbo_ext_uneven(x1, x2, p = 0.9)
  # } else if (length(x1) == length(x2)) {
  #   rbo_ext_even(x1, x2, p = 0.9)
  #   } else {
  #   NA
  # }
  
  # if (length(x1) >= length(x2)) {
  #   rbo_ext_even(x1[1:length(x2)], x2, p = 0.9)
  # } else {
  #   rbo_ext_even(x1, x2[1:length(x1)], p = 0.9)
  # }
  
}

rankings <- split(select(films_selection, name_film, rank), films_selection$source)
  
mt <- matrix(nrow = length(rankings), ncol = length(rankings))

for (i in seq_along(rankings)) {
  for (j in seq_along(rankings)) {
    # message("Comparing ", names(rankings)[i], " with ", names(rankings)[j])
    mt[i, j] <- compare_vectors(rankings[[i]], rankings[[j]])
  }
}

colnames(mt) <- names(rankings)

dat <- mt |> 
  as.data.frame() |> 
  as_tibble() |> 
  mutate(name_row = names(rankings), .before = 0) |> 
  pivot_longer(cols = -name_row, names_to = "name_col")

sources <- c(
  "criticker", "letterboxd", "imdb", "empire", "afi", "bfi", "timeout", "variety"
  )

short_names <- c("Criticker", "LetterBoxd", "IMDB", "Empire", "AFI", "BFI", "Timeout",
                 "Variety")

dat <- dat |> 
  mutate(
    name_row = factor(name_row, levels = names(rankings), labels = short_names),
    name_col = factor(name_col, levels = names(rankings), labels = short_names),
    name_col = forcats::fct_rev(name_col)
  )

dat <- dat |> 
  mutate(value = if_else(value > 0.99, NA, value))

ggplot(dat, aes(x = name_row, y = name_col)) +
  geom_tile(aes(fill = value), color = "white") +
  geom_text(aes(label = round(value * 100, 1))) +
  scale_fill_fermenter(direction = 1, breaks = c(0, 0.2, 0.4, 0.6, 0.8)) +
  guides(fill = "none") +
  labs(x = NULL, y = NULL) +
  theme_minimal(base_family = "Raleway") +
  theme(panel.grid = element_blank())

```

Overall, the public rankings are most similar to other public rankings and dissimilar to critic's rankings. Letterboxd has a high similarity with Criticker and IMDB and a low similarity with Variety and Timeout. Likewise, Variety's list is most similar to AFI, BFI, and Timeout.

# Conclusion

This was mostly a "fun" post comparing lists of movie rankings.

-   **Differences Between Critic and Public Rankings**: Movie rankings created by critics and the public show clear differences. Critics' lists tend to be quite consistent and often favor older films. In contrast, rankings based on public online votes are also similar to each other, but generally give more weight to recent films.

-   **The Favoritism of Recent Movies in Public Rankings**: Online public rankings tend to highlight newer movies, especially those from the 2000s. This trend may be influenced by the **age demographic of voters** and the greater availability of more recent movies in online streaming platforms relatively to older movies.

-   **Experts, critics, and the Golden Age of Movies**: Rankings by experts and critics are generally aligned, with similar films appearing in both lists. These rankings tend to include fewer recent releases, with most of the **top films coming from the 1940s, 1960s, and 1970s**.

-   **Limitations**: as noted above, only a handful of these lists are directly comparable. Each list has a different methodology and was published at different times. The online lists (IMDB, Criticker, and LetterBoxd) are the most comparable.
